{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from TCGAMultiOmics.multiomics import MultiOmicsData\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n",
    "\n",
    "from moge.visualization.plot_data import matrix_heatmap, bar_chart\n",
    "from moge.network.edge_generator import DataGenerator\n",
    "from moge.visualization.visualize_embedding import visualize_embedding, plot_bokeh_graph\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moge/data/luad_data_multi_U-T.pickle', 'rb') as file:\n",
    "    luad_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 43307\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "with open('moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.train.pickle', 'rb') as file:\n",
    "# with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.latest.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    network.multi_omics_data = luad_data\n",
    "    network.preprocess_graph()\n",
    "    network.process_genes_info()\n",
    "\n",
    "network.G.remove_edges_from([(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 58591\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ edgelists\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)\n",
    "    network_val.multi_omics_data = luad_data\n",
    "    network_val.preprocess_graph()\n",
    "    network_val.process_genes_info()\n",
    "\n",
    "network_val.G.remove_edges_from([(u,v,d) for u,v,d in network_val.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('moge/data/luad_data_shortest.pickle', 'rb') as file:\n",
    "#     luad_data = pickle.load(file)\n",
    "#     network.multi_omics_data = luad_data\n",
    "#     network.process_genes_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32741.000000\n",
       "mean      1467.542867\n",
       "std       1796.505885\n",
       "min         41.000000\n",
       "50%        767.000000\n",
       "75%       1902.000000\n",
       "85%       2727.000000\n",
       "90%       3475.000000\n",
       "95%       4727.000000\n",
       "99%       8212.400000\n",
       "max      91667.000000\n",
       "Name: Transcript length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.genes_info[\"Transcript length\"] = network.genes_info[\"Transcript sequence\"].apply(lambda x: len(x) if type(x) == str else len(x[np.random.choice(len(x))]) if type(x)==list else None)\n",
    "network.genes_info[\"Transcript length\"].describe(percentiles=[.50, .75, .85, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"d\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u_n\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test data to recall\n",
    "# matrix_heatmap(network_val.get_adjacency_matrix(edge_types=[\"d\"], node_list=network_val.node_list).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'weighted': True,\n",
    " 'undirected_distance': 'euclidean',\n",
    " 'truncating': 'random',\n",
    " 'source_target_dense_layers': True,\n",
    " 'negative_sampling_ratio': 2.0,\n",
    " 'max_length': 5050,\n",
    " 'max2_pool_size': 2,\n",
    " 'max1_pool_size': 9,\n",
    " 'margin': 1.0,\n",
    " 'lstm_unit_size': 100,\n",
    " 'lr': 0.0005,\n",
    " 'embedding_normalization': False,\n",
    " 'directed_proba': 0.5,\n",
    " 'directed_distance': 'euclidean',\n",
    " 'dense2_unit_size': 256,\n",
    " 'dense1_unit_size': 256,\n",
    " 'd': 128,\n",
    " 'conv2_kernel_size': 12,\n",
    " 'conv2_batch_norm': False,\n",
    " 'conv1_kernel_size': 26,\n",
    " 'conv1_batch_norm': False,\n",
    " 'compression_func': 'log'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directed_margin 1.0 , undirected_margin 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseOnlineTripletGraphEmbedding(batch_size=225, compression_func='log',\n",
       "                  conv1_batch_norm=False, conv1_kernel_size=26,\n",
       "                  conv2_batch_norm=False, conv2_kernel_size=12, d=128,\n",
       "                  dense1_unit_size=256, dense2_unit_size=256,\n",
       "                  directed_distance='euclidean', directed_proba=0.5,\n",
       "                  embedding_normalization=False, epochs=200, lr=0.0005,\n",
       "                  lstm_unit_size=100, margin=1.0, max1_pool_size=9,\n",
       "                  max2_pool_size=2, max_length=5050,\n",
       "                  negative_sampling_ratio=2.0, seed=0,\n",
       "                  source_target_dense_layers=True, truncating='random',\n",
       "                  undirected_distance='euclidean', verbose=True,\n",
       "                  weighted=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moge.embedding.siamese_graph_embedding import SiameseGraphEmbedding\n",
    "from moge.embedding.siamese_triplet_online_embedding import SiameseOnlineTripletGraphEmbedding\n",
    "\n",
    "siamese = SiameseOnlineTripletGraphEmbedding(batch_size=225, margin=params[\"margin\"], epochs=200, verbose=True)\n",
    "# siamese = SiameseGraphEmbedding(batch_size=425, epochs=10, verbose=True)\n",
    "\n",
    "# siamese = SiameseTripletGraphEmbedding(d=128, batch_size=256, margin=0.2, lr=0.001, epochs=30, \n",
    "#     negative_sampling_ratio=2.0, directed_proba=0.8, compression_func=\"sqrt3\",\n",
    "#     max_length=2000, truncating=\"post\", verbose=True)\n",
    "\n",
    "siamese.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# with open(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/params.txt\", \"r\") as file:\n",
    "#     params = yaml.load(str(file.read()))\n",
    "#     params[\"subsample\"] = False\n",
    "# #     params[\"batch_size\"] = 105\n",
    "#     siamese.set_params(**params)\n",
    "#     file.close()\n",
    "    \n",
    "# siamese.load_model(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/lstm_model.e5.h5\", network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index: {'A': 1, 'T': 2, 'G': 3, 'C': 4}\n",
      "# of nodes to sample from (non-zero degree): 31590\n",
      "# of nodes to sample from (non-zero degree): 4109\n",
      "labels_directed SparseTensor(indices=Tensor(\"labels_directed/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_directed/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_directed/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "labels_undirected SparseTensor(indices=Tensor(\"labels_undirected/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_undirected/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_undirected/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "Embedding Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, ?, 4), dtype=float32, device=/device:GPU:0)\n",
      "conv2D Tensor(\"lstm_lambda_2/Squeeze:0\", shape=(?, ?, 320), dtype=float32, device=/device:GPU:0)\n",
      "conv1d_2 Tensor(\"lstm_conv_2/Relu:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "max pooling_2 Tensor(\"max_pooling1d_2/Squeeze:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "brnn Tensor(\"bidirectional_1/concat_2:0\", shape=(?, 200), dtype=float32, device=/device:GPU:0)\n",
      "source Tensor(\"dense_source/BiasAdd:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "target Tensor(\"dense_target/BiasAdd:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "embedding Tensor(\"embedding_output/concat:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "embeddings Tensor(\"lstm_network/embedding_output/concat:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "directed_pairwise_distances Tensor(\"directed_pairwise_distances/mul_2:0\", shape=(?, ?), dtype=float32, device=/device:GPU:0)\n",
      "Network total weights: 1090644\n",
      "log_dir: logs/SiameseOnlineTriplet_04-29_11-38PM\n",
      "Epoch 1/200\n",
      " 506/1000 [==============>...............] - ETA: 1:39 - loss: 0.3375 - _precision: 0.5213 - _recall: 0.6441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-62:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jonny/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/triplet_generator.py\", line 125, in __getitem__\n",
      "    X, y = self.__data_generation(sampled_nodes)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/jonny/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/triplet_generator.py\", line 137, in __data_generation\n",
      "    X[\"input_seqs\"] = self.get_sequence_data(sampled_nodes, variable_length=False)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jonny/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/edge_generator.py\", line 337, in get_sequence_data\n",
      "    maxlen=self.maxlen)\n",
      "  File \"/home/jonny/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/edge_generator.py\", line 355, in encode_texts\n",
      "    encoded = self.tokenizer.texts_to_sequences(texts)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/keras_preprocessing/text.py\", line 313, in texts_to_sequences_generator\n",
      "    i = self.word_index.get(w)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese.learn_embedding(network, network_val=network_val, \n",
    "                        multi_gpu=False, rebuild_model=False,\n",
    "                        n_steps=1000, \n",
    "                        tensorboard=True, embeddings=True, histogram_freq=1,\n",
    "                        early_stopping=0,\n",
    "#                         initial_epoch=0,\n",
    "                        seed=0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsiamese.get_callbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fd876a808d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msiamese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bwr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/embedding/siamese_graph_embedding.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(self, variable_length, recompute, node_list, minlen)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_X\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrecompute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/embedding/siamese_graph_embedding.py\u001b[0m in \u001b[0;36mprocess_embeddings\u001b[0;34m(self, variable_length, batch_size, minlen)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sequence_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/edge_generator.py\u001b[0m in \u001b[0;36mget_sequence_data\u001b[0;34m(self, node_list, variable_length, minlen)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             padded_encoded_sequences = self.encode_texts(self.genes_info.loc[node_list, \"Transcript sequence\"],\n\u001b[0;32m--> 337\u001b[0;31m                                                          maxlen=self.maxlen)\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             padded_encoded_sequences = [\n",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/edge_generator.py\u001b[0m in \u001b[0;36mencode_texts\u001b[0;34m(self, texts, maxlen, minlen)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# integer encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mbatch_maxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                             self.split)\n\u001b[1;32m    311\u001b[0m             \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matrix_heatmap(siamese.get_embedding(recompute=True), cmap=\"bwr\", aspect='auto', figsize=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delattr(siamese, \"reconstructed_adj\") if hasattr(siamese, \"reconstructed_adj\") else None\n",
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"d\", \n",
    "#                                              interpolate=False,\n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(),\n",
    "                                            ), figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"u\", \n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(), \n",
    "                                             ), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.save_model(\"lstm_model.h5\", model=\"lstm\", logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.truncating = \"post\"\n",
    "# siamese.save_embeddings(\"lmn_train.batch_contrastive.euclidean.longest.trunc5050.emb\", \n",
    "#                         variable_length=False, recompute=False, minlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.embedding.static_graph_embedding import ImportedGraphEmbedding\n",
    "from moge.embedding.sequence_based_embedding import BioVecEmbedding, iDeepVEmbedding, LncTarInteraction\n",
    "\n",
    "nodelist = network.genes_info.index.tolist()\n",
    "\n",
    "# biovec_emb = BioVecEmbedding(network, {\"MIR\": \"moge/data/biovec/miRNA_protvec.model\",\n",
    "#                          \"GE\": \"moge/data/biovec/mRNA_protvec.model\",\n",
    "#                          \"LNC\": \"moge/data/biovec/lncRNA_protvec.model\"})\n",
    "\n",
    "node2vec_emb = ImportedGraphEmbedding(d=128, method_name=\"node2vec\")\n",
    "node2vec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.node2vec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "biovec_emb = ImportedGraphEmbedding(d=100, method_name=\"BioVec\")\n",
    "biovec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.biovec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "line_emb = ImportedGraphEmbedding(d=128, method_name=\"LINE\")\n",
    "line_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.line.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "hope_emb = ImportedGraphEmbedding(d=128, method_name=\"HOPE\")\n",
    "hope_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.hope.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "sdne_emb = ImportedGraphEmbedding(d=128, method_name=\"SDNE\")\n",
    "sdne_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.sdne.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "rna2rna_emb = ImportedGraphEmbedding(d=128, method_name=\"rna2rna\")\n",
    "rna2rna_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/lmn_train.siamese.multi_seq_UT.biogrid.full.euclidean.trunc.emb\", \n",
    "                         node_list=network.node_list)\n",
    "rna2rna_emb.network = network\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rna2rna_graph = nx.from_numpy_matrix(rna2rna_emb.get_reconstructed_adj(), create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delattr(rna2rna_emb, \"reconstructed_adj\") if hasattr(rna2rna_emb, \"reconstructed_adj\") else None\n",
    "# matrix_heatmap(rna2rna_emb.get_reconstructed_adj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {}\n",
    "methods[\"node2vec\"] = node2vec_emb\n",
    "methods[\"LINE\"] = line_emb\n",
    "methods[\"HOPE\"] = hope_emb\n",
    "methods[\"SDNE\"] = sdne_emb\n",
    "methods[\"BioVec\"] = biovec_emb\n",
    "# methods[\"rna2rna\"] = rna2rna_emb\n",
    "methods[\"rna2rna\"] = siamese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v2.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase Predicted\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 7.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.5\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v3.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = nx.isolates(network_val.G)\n",
    "network_val.G.remove_nodes_from(list(isolates))\n",
    "isolates = nx.isolates(network.G)\n",
    "network.G.remove_nodes_from(list(isolates))\n",
    "novel_nodes = list(set(network_val.G.nodes()) - set(network.G.nodes()))\n",
    "print(len(novel_nodes), {modality:len(set(novel_nodes) & set(network.nodes[modality])) for modality in [\"LNC\", \"MIR\", \"GE\"]})\n",
    "novel_edges = list(network_val.G.edges(novel_nodes, data=True))\n",
    "print(len(novel_edges))\n",
    "network_val.G.clear()\n",
    "network_val.G.add_edges_from(novel_edges)\n",
    "\n",
    "generator_val_novel = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val_novel.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val_novel, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training set (for graph reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.edge_generator import DataGenerator\n",
    "\n",
    "generator_train = DataGenerator(network=network, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1)\n",
    "generator_train.Eu_count = 0\n",
    "generator_train.En_count = 0\n",
    "generator_train.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_train, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_top_k_link_pred\n",
    "\n",
    "database_tests = [\n",
    "    (\"LNC\", \"GE\", \"lncrna2target\"),\n",
    "    (\"MIR\", \"LNC\", \"lncBase\"),\n",
    "    (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "    (\"GE\", \"GE\", \"BioGRID\"), \n",
    "    (\"LNC\", \"MIR\", \"lncRInter\"),\n",
    "    # (\"LNC\", \"GE\", \"LncReg\"),\n",
    "]\n",
    "top_k = 5000\n",
    "\n",
    "for source, target, database in database_tests:\n",
    "    print(database)\n",
    "    results = {}\n",
    "    for method in methods.keys():\n",
    "        results[method] = \\\n",
    "              evaluate_top_k_link_pred(methods[method], network_train=network, network_test=network_val, \n",
    "                                       node_list=set(network.nodes[source])|set(network_val.nodes[source]), \n",
    "                                       node_list_B=set(network.nodes[target])|set(network_val.nodes[target]), \n",
    "                                       edge_type=\"d\", databases=[database], top_k=top_k)\n",
    "        \n",
    "    bar_chart(results, measures=['precision', 'recall'], \n",
    "              title=\"Top-k (k={}) Predictions on {}\".format(top_k, database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"locus_type\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "print(results)\n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'],\n",
    "         title=\"Clustering Evaluation to {}\".format(\"RNA Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"Family\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "print(results)\n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'], \n",
    "          title=\"Clustering Evaluation to {}\".format(\"RNA Family\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Family\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Disease association\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.utils import get_scalefree_fit_score\n",
    "\n",
    "results = {}\n",
    "modalities = [(\"MIR\", \"LNC\"), (\"LNC\", \"MIR\"), (\"LNC\", \"GE\"), (\"MIR\", \"GE\"), (\"GE\", \"GE\")]\n",
    "labels = [\"miRNA-lncRNA\", \"lncRNA-miRNA\", \"lncRNA-mRNA\", \"miRNA-mRNA\", \"mRNA-mRNA\"]\n",
    "databases = [\"lncBase\", \"NPInter\", \"lncrna2target\", \"miRTarBase\", \"BioGRID\"]\n",
    "\n",
    "for method in [\"Databases\"]+list(methods.keys()):\n",
    "    if method == \"BioVec\":\n",
    "        continue\n",
    "    elif method == \"Databases\":\n",
    "        sub_result = {}\n",
    "        for (A, B), label, database in zip(modalities, labels, databases):\n",
    "            adj = network.get_adjacency_matrix(edge_types=[\"d\"], \n",
    "                                               node_list=network.node_list,\n",
    "                                               databases=[database,])\n",
    "            network_degrees = np.sum(adj, axis=1)\n",
    "            sub_result[label] = get_scalefree_fit_score(network_degrees, plot=False)\n",
    "        results[method] = sub_result\n",
    "    else:\n",
    "        sub_result = {}\n",
    "        for (A, B), label in zip(modalities, labels):\n",
    "           sub_result[label] = methods[method].get_scalefree_fit_score(network.nodes[A], network.nodes[B])\n",
    "        results[method] = sub_result\n",
    "    \n",
    "bar_chart(results, measures=labels, title=\"Scale-free fit scores\", loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize lncRNA Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = [(\"MIR\", \"LNC\", \"lncBase\"), \n",
    "              (\"LNC\", \"MIR\", \"NPInter\"), \n",
    "              (\"LNC\", \"GE\", \"lncrna2target\"), \n",
    "              (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "              (\"GE\", \"GE\", \"BioGRID\")\n",
    "             ]\n",
    "\n",
    "nodes_inters_dict = {}\n",
    "for A, B, database in modalities:\n",
    "    edge_list = [(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and d[\"database\"]==database and\\\n",
    "                u in network.nodes[A] and v in network.nodes[B]]\n",
    "    nodes_inters_dict[(A, B)] = {}\n",
    "    nodes_inters_dict[(A, B)][A] = {u for u,v,d in edge_list}\n",
    "    nodes_inters_dict[(A, B)][B] = {v for u,v,d in edge_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_inters_dict_2 = dict.fromkeys(rna2rna_emb.node_list, 0)\n",
    "\n",
    "for A, B, database in modalities:\n",
    "    if database == \"BioGRID\": continue\n",
    "    for node in nodes_inters_dict[(A, B)][A]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "    for node in nodes_inters_dict[(A, B)][B]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "        \n",
    "trimodule_nodes = [k for k,v in nodes_inters_dict_2.items() if (k in network.nodes[\"LNC\"] and v >= 2) or \\\n",
    "                   (k in network.nodes[\"MIR\"] and v >= 2) or \\\n",
    "                  (k in network.nodes[\"GE\"] and v >= 2)]\n",
    "[(m, len(set(trimodule_nodes) & set(network.nodes[m]))) for m in [\"LNC\", \"MIR\", \"GE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(trimodule_nodes) & set(network.nodes[\"LNC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = network.G.subgraph(trimodule_nodes).to_undirected()\n",
    "center_node = \"HOTAIR\"\n",
    "nodelist = list(g.neighbors(center_node))+[center_node]\n",
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_edges = siamese.get_top_k_predicted_edges(edge_type=\"d\", top_k=50, \n",
    "                                  node_list=[center_node],\n",
    "                                  node_list_B=siamese.node_list,\n",
    "                                  training_network=network,)\n",
    "predicted_edges[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred_edges = 10\n",
    "predicted_edges_filter = [(u,v) for u,v,d in predicted_edges[:n_pred_edges] if u in siamese.node_list and v in siamese.node_list]\n",
    "nodelist = list(set(nodelist) | {node for pair in predicted_edges_filter for node in pair})\n",
    "true_edges = network.get_edgelist(node_list=nodelist, inclusive=True)\n",
    "edgelist = true_edges + predicted_edges_filter\n",
    "edge_colors = [10,]*len(true_edges) + [0,]*len(predicted_edges_filter)\n",
    "linewidths = [0.4,]*len(true_edges) + [1.2,]*len(predicted_edges_filter)\n",
    "print(len(edgelist), len(edge_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = nx.spring_layout(network.G.subgraph(nodelist), \n",
    "#                           weight='weight',\n",
    "                          k=15.0/len(nodelist)**0.5,\n",
    "                          iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# siamese.process_embeddings(variable_length=True, minlen=200)\n",
    "# delattr(siamese, \"node_pos\")\n",
    "visualize_embedding(siamese, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"RNA Type\",\n",
    "                    figsize=(8,8), dpi=150,\n",
    "                    node_size=\"centrality\", \n",
    "                    edgelist=edgelist, width=linewidths,\n",
    "                    edge_color=edge_colors, edge_cmap=plt.cm.RdBu, \n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=7,\n",
    "                    cmap=\"viridis\",\n",
    "                    file_name=\"moge/data/Results/vis_lncRNAs/{}\".format(center_node),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize RNA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(rna2rna_emb, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"locus_type\", # sc.tolist(), \n",
    "                    top_k=0,\n",
    "                    edgelist=network.get_edgelist(node_list=nodelist, inclusive=True),\n",
    "#                     test_nodes=siamese.generator_val.get_nonzero_nodelist(),\n",
    "                    cmap=\"gist_ncar\",\n",
    "                    node_size=\"centrality\", \n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=9,\n",
    "                    figsize=(10,10), dpi=150,\n",
    "#                     file_name=\"moge/data/Results/siamese_online_triplet_euclidean\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.process_embeddings(variable_length=True, minlen=200)\n",
    "# delattr(siamese, \"node_pos\")\n",
    "visualize_embedding(siamese, network=network, node_label=\"locus_type\", \n",
    "                    cmap=\"gist_ncar\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(network.G.subgraph(nodelist), \"./moge/data/Networks/{}.edgelist\".format(center_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bokeh_graph(network.G.subgraph(nodelist), node_pos=layout,\n",
    "                 node_label=network.genes_info.loc[nodelist, \"locus_type\"].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
