{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from TCGAMultiOmics.multiomics import MultiOmicsData\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n",
    "\n",
    "from moge.visualization.plot_data import matrix_heatmap, bar_chart\n",
    "from moge.network.edge_generator import DataGenerator\n",
    "from moge.visualization.visualize_embedding import visualize_embedding, plot_bokeh_graph\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moge/data/luad_data_multi_U-T.pickle', 'rb') as file:\n",
    "    luad_data = pickle.load(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.heterogeneous_network import get_rename_dict\n",
    "noncode_rename_dict = pd.Series(luad_data.LNC.noncode_func_df[\"Gene Name\"].values,\n",
    "     index=luad_data.LNC.noncode_func_df[\"NONCODE Gene ID\"].str.split(\".\", expand=True)[0]).to_dict()\n",
    "noncode_rename_dict = {k: noncode_rename_dict[k] for k in noncode_rename_dict if type(noncode_rename_dict[k])!=float}\n",
    "\n",
    "lncbase_rename_dict = get_rename_dict(luad_data.LNC.get_genes_info(), \"Gene ID\")\n",
    "lncbase_rename_dict.update(noncode_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 58980\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "# with open('moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.train.pickle', 'rb') as file:\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.latest.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    network.preprocess_graph()\n",
    "    network.process_genes_info()\n",
    "    network.multi_omics_data = luad_data\n",
    "network.G.remove_edges_from([(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 58986\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ edgelists\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test_v2.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)\n",
    "    network_val.preprocess_graph()\n",
    "    network_val.process_genes_info()\n",
    "    network_val.multi_omics_data = luad_data\n",
    "\n",
    "network_val.G.remove_edges_from([(u,v,d) for u,v,d in network_val.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])\n",
    "network_val.G = nx.relabel_nodes(network_val.G, lncbase_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('moge/data/luad_data_shortest.pickle', 'rb') as file:\n",
    "#     luad_data = pickle.load(file)\n",
    "#     network.multi_omics_data = luad_data\n",
    "#     network.process_genes_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32741.000000\n",
       "mean       791.396109\n",
       "std       1132.424500\n",
       "min         41.000000\n",
       "50%        518.000000\n",
       "75%        726.000000\n",
       "85%       1112.000000\n",
       "90%       1697.000000\n",
       "95%       2553.000000\n",
       "99%       5047.600000\n",
       "max      91667.000000\n",
       "Name: Transcript length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.genes_info[\"Transcript length\"] = network.genes_info[\"Transcript sequence\"].apply(lambda x: len(x) if type(x) == str else None)\n",
    "network.genes_info[\"Transcript length\"].describe(percentiles=[.50, .75, .85, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"d\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u_n\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test data to recall\n",
    "# matrix_heatmap(network_val.get_adjacency_matrix(edge_types=[\"d\"], node_list=network_val.node_list).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'weighted': True,\n",
    " \n",
    " 'truncating': 'random',\n",
    " 'source_target_dense_layers': True,\n",
    " 'negative_sampling_ratio': 5.0,\n",
    " 'max_length': 5050,\n",
    " 'max2_pool_size': 6,\n",
    " 'max1_pool_size': 9,\n",
    " 'margin': 1.0,\n",
    " 'lstm_unit_size': 320,\n",
    " 'lr': 0.0005,\n",
    " 'embedding_normalization': False,\n",
    " 'directed_proba': 1.0,\n",
    "    'directed_distance': 'dot_sigmoid',\n",
    "    'undirected_distance': 'dot_softmax',\n",
    " 'dense2_unit_size': None,\n",
    " 'dense1_unit_size': 512,\n",
    " 'd': 128,\n",
    " 'conv2_kernel_size': 6,\n",
    " 'conv2_batch_norm': True,\n",
    " 'conv1_kernel_size': 6,\n",
    " 'conv1_batch_norm': True,\n",
    " 'compression_func': 'sqrt3'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directed_margin 1.0 , undirected_margin 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseOnlineTripletGraphEmbedding(batch_size=225, compression_func='sqrt3',\n",
       "                  conv1_batch_norm=True, conv1_kernel_size=6,\n",
       "                  conv2_batch_norm=True, conv2_kernel_size=6, d=128,\n",
       "                  dense1_unit_size=512, dense2_unit_size=None,\n",
       "                  directed_distance='dot_sigmoid', directed_proba=1.0,\n",
       "                  embedding_normalization=False, epochs=200, lr=0.0005,\n",
       "                  lstm_unit_size=320, margin=1.0, max1_pool_size=9,\n",
       "                  max2_pool_size=6, max_length=5050,\n",
       "                  negative_sampling_ratio=5.0, seed=0,\n",
       "                  source_target_dense_layers=True, truncating='random',\n",
       "                  undirected_distance='dot_softmax', verbose=True,\n",
       "                  weighted=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moge.embedding.siamese_graph_embedding import SiameseGraphEmbedding\n",
    "from moge.embedding.siamese_triplet_online_embedding import SiameseOnlineTripletGraphEmbedding\n",
    "\n",
    "siamese = SiameseOnlineTripletGraphEmbedding(batch_size=225, margin=params[\"margin\"], epochs=200, verbose=True)\n",
    "# siamese = SiameseGraphEmbedding(batch_size=425, epochs=10, verbose=True)\n",
    "\n",
    "# siamese = SiameseTripletGraphEmbedding(d=128, batch_size=256, margin=0.2, lr=0.001, epochs=30, \n",
    "#     negative_sampling_ratio=2.0, directed_proba=0.8, compression_func=\"sqrt3\",\n",
    "#     max_length=2000, truncating=\"post\", verbose=True)\n",
    "\n",
    "siamese.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# with open(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/params.txt\", \"r\") as file:\n",
    "#     params = yaml.load(str(file.read()))\n",
    "#     params[\"subsample\"] = False\n",
    "# #     params[\"batch_size\"] = 105\n",
    "#     siamese.set_params(**params)\n",
    "#     file.close()\n",
    "    \n",
    "# siamese.load_model(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/lstm_model.e5.h5\", network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index: {'A': 1, 'G': 2, 'T': 3, 'C': 4}\n",
      "# of nodes to sample from (non-zero degree): 31623\n",
      "# of nodes to sample from (non-zero degree): 4113\n",
      "labels_directed SparseTensor(indices=Tensor(\"labels_directed/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_directed/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_directed/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "labels_undirected SparseTensor(indices=Tensor(\"labels_undirected/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_undirected/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_undirected/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "Embedding Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, ?, 4), dtype=float32, device=/device:GPU:0)\n",
      "conv2D Tensor(\"lstm_lambda_2/Squeeze:0\", shape=(?, ?, 320), dtype=float32, device=/device:GPU:0)\n",
      "conv1d_2 Tensor(\"lstm_conv_2/Relu:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "max pooling_2 Tensor(\"max_pooling1d_2/Squeeze:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "brnn Tensor(\"bidirectional_1/concat_2:0\", shape=(?, 640), dtype=float32, device=/device:GPU:0)\n",
      "source Tensor(\"dense_source/BiasAdd:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "target Tensor(\"dense_target/BiasAdd:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "embedding Tensor(\"batch_normalization_1/cond/Merge:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "embeddings Tensor(\"lstm_network/batch_normalization_1/cond/Merge:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "directed_pairwise_distances Tensor(\"directed_pairwise_distances/Sigmoid:0\", shape=(?, ?), dtype=float32, device=/device:GPU:0)\n",
      "Network total weights: 2089108\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 313s 313ms/step - loss: 0.3799 - _precision: 0.2756 - _recall: 0.1251 - val_loss: nan - val__precision: 0.3422 - val__recall: 1.0000\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 298s 298ms/step - loss: 0.3192 - _precision: 0.2546 - _recall: 0.0186 - val_loss: nan - val__precision: 0.3964 - val__recall: 0.0460\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.3180 - _precision: 0.2289 - _recall: 0.0149 - val_loss: nan - val__precision: 0.3409 - val__recall: 1.0000\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.3146 - _precision: 0.2714 - _recall: 0.0197 - val_loss: nan - val__precision: 0.3810 - val__recall: 0.0390\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.3054 - _precision: 0.4627 - _recall: 0.0706 - val_loss: nan - val__precision: 0.7870 - val__recall: 0.0339\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2957 - _precision: 0.6147 - _recall: 0.1738 - val_loss: nan - val__precision: 0.8554 - val__recall: 0.2658\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2873 - _precision: 0.6454 - _recall: 0.2627 - val_loss: nan - val__precision: 0.8584 - val__recall: 0.1364\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2783 - _precision: 0.6772 - _recall: 0.3519 - val_loss: nan - val__precision: 0.6560 - val__recall: 0.0234\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2706 - _precision: 0.6966 - _recall: 0.4051 - val_loss: nan - val__precision: 0.8157 - val__recall: 0.1003\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2627 - _precision: 0.7057 - _recall: 0.4429 - val_loss: nan - val__precision: 0.8475 - val__recall: 0.1079\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2547 - _precision: 0.7134 - _recall: 0.4698 - val_loss: nan - val__precision: 0.6702 - val__recall: 0.0390\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2480 - _precision: 0.7238 - _recall: 0.4973 - val_loss: nan - val__precision: 0.3405 - val__recall: 1.0000\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2405 - _precision: 0.7325 - _recall: 0.5325 - val_loss: nan - val__precision: 0.8076 - val__recall: 0.1301\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2348 - _precision: 0.7383 - _recall: 0.5587 - val_loss: nan - val__precision: 0.8579 - val__recall: 0.1771\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2302 - _precision: 0.7480 - _recall: 0.5773 - val_loss: nan - val__precision: 0.7714 - val__recall: 0.0465\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2262 - _precision: 0.7575 - _recall: 0.5995 - val_loss: nan - val__precision: 0.8449 - val__recall: 0.0939\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2231 - _precision: 0.7672 - _recall: 0.6146 - val_loss: nan - val__precision: 0.8874 - val__recall: 0.1493\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2194 - _precision: 0.7734 - _recall: 0.6269 - val_loss: nan - val__precision: 0.8337 - val__recall: 0.0652\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2169 - _precision: 0.7803 - _recall: 0.6398 - val_loss: nan - val__precision: 0.8271 - val__recall: 0.0884\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2139 - _precision: 0.7871 - _recall: 0.6472 - val_loss: nan - val__precision: 0.8591 - val__recall: 0.2262\n",
      "Epoch 24/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2103 - _precision: 0.7924 - _recall: 0.6630Epoch 24/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2103 - _precision: 0.7925 - _recall: 0.6630 - val_loss: nan - val__precision: 0.8709 - val__recall: 0.1574\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2074 - _precision: 0.8007 - _recall: 0.6724 - val_loss: nan - val__precision: 0.8224 - val__recall: 0.1020\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2055 - _precision: 0.8011 - _recall: 0.6765 - val_loss: nan - val__precision: 0.7972 - val__recall: 0.0779\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.2030 - _precision: 0.8055 - _recall: 0.6825 - val_loss: nan - val__precision: 0.8568 - val__recall: 0.1316\n",
      "Epoch 28/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2010 - _precision: 0.8114 - _recall: 0.6952Epoch 28/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.2010 - _precision: 0.8114 - _recall: 0.6953 - val_loss: nan - val__precision: 0.8842 - val__recall: 0.1171\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1995 - _precision: 0.8095 - _recall: 0.6967 - val_loss: nan - val__precision: 0.8800 - val__recall: 0.1335\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1984 - _precision: 0.8128 - _recall: 0.7016 - val_loss: nan - val__precision: 0.9022 - val__recall: 0.1082\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1962 - _precision: 0.8161 - _recall: 0.7087 - val_loss: nan - val__precision: 0.8621 - val__recall: 0.1218\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1946 - _precision: 0.8212 - _recall: 0.7117 - val_loss: nan - val__precision: 0.8665 - val__recall: 0.1674\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1928 - _precision: 0.8216 - _recall: 0.7216 - val_loss: nan - val__precision: 0.8796 - val__recall: 0.0936\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1916 - _precision: 0.8252 - _recall: 0.7270 - val_loss: nan - val__precision: 0.8625 - val__recall: 0.1756\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1903 - _precision: 0.8270 - _recall: 0.7295 - val_loss: nan - val__precision: 0.8782 - val__recall: 0.1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1892 - _precision: 0.8287 - _recall: 0.7321 - val_loss: nan - val__precision: 0.8869 - val__recall: 0.1837\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1880 - _precision: 0.8313 - _recall: 0.7374 - val_loss: nan - val__precision: 0.8846 - val__recall: 0.1627\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1869 - _precision: 0.8348 - _recall: 0.7397 - val_loss: nan - val__precision: 0.8510 - val__recall: 0.1220\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1853 - _precision: 0.8356 - _recall: 0.7463 - val_loss: nan - val__precision: 0.8564 - val__recall: 0.1110\n",
      "Epoch 40/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1841 - _precision: 0.8393 - _recall: 0.7504Epoch 40/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1841 - _precision: 0.8393 - _recall: 0.7505 - val_loss: nan - val__precision: 0.8913 - val__recall: 0.1199\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1833 - _precision: 0.8402 - _recall: 0.7571 - val_loss: nan - val__precision: 0.8810 - val__recall: 0.1507\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1820 - _precision: 0.8448 - _recall: 0.7584 - val_loss: nan - val__precision: 0.8701 - val__recall: 0.1728\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1810 - _precision: 0.8462 - _recall: 0.7640 - val_loss: nan - val__precision: 0.8839 - val__recall: 0.1733\n",
      "Epoch 44/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1803 - _precision: 0.8480 - _recall: 0.7678Epoch 44/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1803 - _precision: 0.8476 - _recall: 0.7675 - val_loss: nan - val__precision: 0.8889 - val__recall: 0.1550\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1791 - _precision: 0.8488 - _recall: 0.7702 - val_loss: nan - val__precision: 0.8880 - val__recall: 0.1402\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1787 - _precision: 0.8514 - _recall: 0.7736 - val_loss: nan - val__precision: 0.8594 - val__recall: 0.1429\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1780 - _precision: 0.8535 - _recall: 0.7759 - val_loss: nan - val__precision: 0.8916 - val__recall: 0.1887\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1768 - _precision: 0.8560 - _recall: 0.7799 - val_loss: nan - val__precision: 0.8848 - val__recall: 0.2136\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1758 - _precision: 0.8593 - _recall: 0.7838 - val_loss: nan - val__precision: 0.8724 - val__recall: 0.1322\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1753 - _precision: 0.8602 - _recall: 0.7858 - val_loss: nan - val__precision: 0.8477 - val__recall: 0.1395\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1745 - _precision: 0.8612 - _recall: 0.7882 - val_loss: nan - val__precision: 0.8686 - val__recall: 0.1624\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1732 - _precision: 0.8646 - _recall: 0.7907 - val_loss: nan - val__precision: 0.8734 - val__recall: 0.1838\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1722 - _precision: 0.8672 - _recall: 0.7945 - val_loss: nan - val__precision: 0.8905 - val__recall: 0.1756\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1718 - _precision: 0.8670 - _recall: 0.7954 - val_loss: nan - val__precision: 0.8572 - val__recall: 0.1586\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1703 - _precision: 0.8689 - _recall: 0.8020 - val_loss: nan - val__precision: 0.8657 - val__recall: 0.1976\n",
      "Epoch 56/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1699 - _precision: 0.8720 - _recall: 0.8021Epoch 56/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1699 - _precision: 0.8721 - _recall: 0.8022 - val_loss: nan - val__precision: 0.8790 - val__recall: 0.1802\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1691 - _precision: 0.8731 - _recall: 0.8056 - val_loss: nan - val__precision: 0.8724 - val__recall: 0.1981\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1688 - _precision: 0.8755 - _recall: 0.8075 - val_loss: nan - val__precision: 0.8696 - val__recall: 0.1653\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1681 - _precision: 0.8756 - _recall: 0.8089 - val_loss: nan - val__precision: 0.8721 - val__recall: 0.2055\n",
      "Epoch 60/200\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1672 - _precision: 0.8774 - _recall: 0.8125Epoch 60/200\n",
      "1000/1000 [==============================] - 300s 300ms/step - loss: 0.1673 - _precision: 0.8771 - _recall: 0.8122 - val_loss: nan - val__precision: 0.8733 - val__recall: 0.1871\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 299s 299ms/step - loss: 0.1663 - _precision: 0.8792 - _recall: 0.8155 - val_loss: nan - val__precision: 0.8792 - val__recall: 0.1939\n",
      "Epoch 62/200\n",
      " 437/1000 [============>.................] - ETA: 2:34 - loss: 0.1594 - _precision: 0.8801 - _recall: 0.8239"
     ]
    }
   ],
   "source": [
    "siamese.learn_embedding(network, network_val=network_val, \n",
    "                        multi_gpu=False, rebuild_model=False,\n",
    "                        n_steps=2000, \n",
    "                        validation_steps=250,\n",
    "                        tensorboard=True,\n",
    "                        early_stopping=0,\n",
    "                        initial_epoch=3,\n",
    "                        seed=0),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_heatmap(siamese.get_embedding(recompute=True), cmap=\"bwr\", aspect='auto', figsize=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delattr(siamese, \"reconstructed_adj\") if hasattr(siamese, \"reconstructed_adj\") else None\n",
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"d\", \n",
    "#                                              interpolate=False,\n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(),\n",
    "                                            ), figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"u\", \n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(), \n",
    "                                             ), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.save_model(\"lstm_model.h5\", model=\"lstm\", logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.truncating = \"post\"\n",
    "# siamese.save_embeddings(\"lmn_train.triplet.shortest.biogrid.full.euclidean.trunc.emb\", \n",
    "#                         variable_length=False, recompute=False, minlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.embedding.static_graph_embedding import ImportedGraphEmbedding\n",
    "from moge.embedding.sequence_based_embedding import BioVecEmbedding, iDeepVEmbedding, LncTarInteraction\n",
    "\n",
    "nodelist = network.genes_info.index.tolist()\n",
    "\n",
    "# biovec_emb = BioVecEmbedding(network, {\"MIR\": \"moge/data/biovec/miRNA_protvec.model\",\n",
    "#                          \"GE\": \"moge/data/biovec/mRNA_protvec.model\",\n",
    "#                          \"LNC\": \"moge/data/biovec/lncRNA_protvec.model\"})\n",
    "\n",
    "node2vec_emb = ImportedGraphEmbedding(d=128, method_name=\"node2vec\")\n",
    "node2vec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.node2vec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "biovec_emb = ImportedGraphEmbedding(d=100, method_name=\"BioVec\")\n",
    "biovec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.biovec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "line_emb = ImportedGraphEmbedding(d=128, method_name=\"LINE\")\n",
    "line_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.line.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "hope_emb = ImportedGraphEmbedding(d=128, method_name=\"HOPE\")\n",
    "hope_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.hope.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "sdne_emb = ImportedGraphEmbedding(d=128, method_name=\"SDNE\")\n",
    "sdne_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.sdne.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "rna2rna_emb = ImportedGraphEmbedding(d=128, method_name=\"rna2rna\")\n",
    "rna2rna_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/lmn_train.siamese.multi_seq_UT.biogrid.full.euclidean.trunc.emb\", \n",
    "                         node_list=network.node_list)\n",
    "rna2rna_emb.network = network\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rna2rna_graph = nx.from_numpy_matrix(rna2rna_emb.get_reconstructed_adj(), create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delattr(rna2rna_emb, \"reconstructed_adj\") if hasattr(rna2rna_emb, \"reconstructed_adj\") else None\n",
    "# matrix_heatmap(rna2rna_emb.get_reconstructed_adj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {}\n",
    "methods[\"node2vec\"] = node2vec_emb\n",
    "methods[\"LINE\"] = line_emb\n",
    "methods[\"HOPE\"] = hope_emb\n",
    "methods[\"SDNE\"] = sdne_emb\n",
    "methods[\"BioVec\"] = biovec_emb\n",
    "# methods[\"rna2rna\"] = rna2rna_emb\n",
    "methods[\"rna2rna\"] = siamese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v2.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase Predicted\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 7.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.5\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v3.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = nx.isolates(network_val.G)\n",
    "network_val.G.remove_nodes_from(list(isolates))\n",
    "isolates = nx.isolates(network.G)\n",
    "network.G.remove_nodes_from(list(isolates))\n",
    "novel_nodes = list(set(network_val.G.nodes()) - set(network.G.nodes()))\n",
    "print(len(novel_nodes), {modality:len(set(novel_nodes) & set(network.nodes[modality])) for modality in [\"LNC\", \"MIR\", \"GE\"]})\n",
    "novel_edges = list(network_val.G.edges(novel_nodes, data=True))\n",
    "print(len(novel_edges))\n",
    "network_val.G.clear()\n",
    "network_val.G.add_edges_from(novel_edges)\n",
    "\n",
    "generator_val_novel = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val_novel.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val_novel, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test_v2.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training set (for graph reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.edge_generator import DataGenerator\n",
    "\n",
    "generator_train = DataGenerator(network=network, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1)\n",
    "generator_train.Eu_count = 0\n",
    "generator_train.En_count = 0\n",
    "generator_train.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_train, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_top_k_link_pred\n",
    "\n",
    "database_tests = [\n",
    "    (\"LNC\", \"GE\", \"lncrna2target\"),\n",
    "    (\"MIR\", \"LNC\", \"lncBase\"),\n",
    "    (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "    (\"GE\", \"GE\", \"BioGRID\"), \n",
    "    (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "    # (\"LNC\", \"GE\", \"LncReg\"),\n",
    "]\n",
    "top_k = 5000\n",
    "\n",
    "for source, target, database in database_tests:\n",
    "    print(database)\n",
    "    results = {}\n",
    "    for method in methods.keys():\n",
    "        results[method] = \\\n",
    "              evaluate_top_k_link_pred(methods[method], network_train=network, network_test=network_val, \n",
    "                                       node_list=set(network.nodes[source])|set(network_val.nodes[source]), \n",
    "                                       node_list_B=set(network.nodes[target])|set(network_val.nodes[target]), \n",
    "                                       edge_type=\"d\", databases=[database], top_k=top_k)\n",
    "        \n",
    "    bar_chart(results, measures=['precision', 'recall'], \n",
    "              title=\"Top-k (k={}) Predictions on {}\".format(top_k, database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"locus_type\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "\n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'],\n",
    "         title=\"Clustering Evaluation to {}\".format(\"RNA Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"Family\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "    \n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'], \n",
    "          title=\"Clustering Evaluation to {}\".format(\"RNA Family\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Family\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Disease association\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.utils import get_scalefree_fit_score\n",
    "\n",
    "results = {}\n",
    "modalities = [(\"MIR\", \"LNC\"), (\"LNC\", \"MIR\"), (\"LNC\", \"GE\"), (\"MIR\", \"GE\"), (\"GE\", \"GE\")]\n",
    "labels = [\"miRNA-lncRNA\", \"lncRNA-miRNA\", \"lncRNA-mRNA\", \"miRNA-mRNA\", \"mRNA-mRNA\"]\n",
    "databases = [\"lncBase\", \"NPInter\", \"lncrna2target\", \"miRTarBase\", \"BioGRID\"]\n",
    "\n",
    "for method in [\"Databases\"]+list(methods.keys()):\n",
    "    if method == \"BioVec\":\n",
    "        continue\n",
    "    elif method == \"Databases\":\n",
    "        sub_result = {}\n",
    "        for (A, B), label, database in zip(modalities, labels, databases):\n",
    "            adj = network.get_adjacency_matrix(edge_types=[\"d\"], \n",
    "                                               node_list=network.node_list,\n",
    "                                               databases=[database,])\n",
    "            network_degrees = np.sum(adj, axis=1)\n",
    "            sub_result[label] = get_scalefree_fit_score(network_degrees, plot=False)\n",
    "        results[method] = sub_result\n",
    "    else:\n",
    "        sub_result = {}\n",
    "        for (A, B), label in zip(modalities, labels):\n",
    "           sub_result[label] = methods[method].get_scalefree_fit_score(network.nodes[A], network.nodes[B])\n",
    "        results[method] = sub_result\n",
    "    \n",
    "bar_chart(results, measures=labels, title=\"Scale-free fit scores\", loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize lncRNA Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = [(\"MIR\", \"LNC\", \"lncBase\"), \n",
    "              (\"LNC\", \"MIR\", \"NPInter\"), \n",
    "              (\"LNC\", \"GE\", \"lncrna2target\"), \n",
    "              (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "              (\"GE\", \"GE\", \"BioGRID\")\n",
    "             ]\n",
    "\n",
    "nodes_inters_dict = {}\n",
    "for A, B, database in modalities:\n",
    "    edge_list = [(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and d[\"database\"]==database and\\\n",
    "                u in network.nodes[A] and v in network.nodes[B]]\n",
    "    nodes_inters_dict[(A, B)] = {}\n",
    "    nodes_inters_dict[(A, B)][A] = {u for u,v,d in edge_list}\n",
    "    nodes_inters_dict[(A, B)][B] = {v for u,v,d in edge_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_inters_dict_2 = dict.fromkeys(rna2rna_emb.node_list, 0)\n",
    "\n",
    "for A, B, database in modalities:\n",
    "    if database == \"BioGRID\": continue\n",
    "    for node in nodes_inters_dict[(A, B)][A]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "    for node in nodes_inters_dict[(A, B)][B]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "        \n",
    "trimodule_nodes = [k for k,v in nodes_inters_dict_2.items() if (k in network.nodes[\"LNC\"] and v >= 2) or \\\n",
    "                   (k in network.nodes[\"MIR\"] and v >= 2) or \\\n",
    "                  (k in network.nodes[\"GE\"] and v >= 2)]\n",
    "[(m, len(set(trimodule_nodes) & set(network.nodes[m]))) for m in [\"LNC\", \"MIR\", \"GE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(trimodule_nodes) & set(network.nodes[\"LNC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = network.G.subgraph(trimodule_nodes).to_undirected()\n",
    "center_node = \"PINK1-AS\"\n",
    "nodelist = list(g.neighbors(center_node))+[center_node]\n",
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_edges = siamese.get_top_k_predicted_edges(edge_type=\"d\", top_k=50, \n",
    "                                  node_list=[center_node],\n",
    "                                  node_list_B=network.node_list,\n",
    "                                  training_network=network,)\n",
    "predicted_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_edges_filter = [(u,v) for u,v,d in predicted_edges[:5]]\n",
    "nodelist = list(set(nodelist) | {node for pair in predicted_edges_filter for node in pair})\n",
    "true_edges = network.get_edgelist(node_list=nodelist, inclusive=True)\n",
    "edgelist = true_edges + predicted_edges_filter\n",
    "edge_colors = [1,]*len(true_edges) + [10,]*len(predicted_edges_filter)\n",
    "print(len(edgelist), len(edge_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = nx.spring_layout(network.G.subgraph(nodelist), \n",
    "#                           weight='weight',\n",
    "                          k=15.0/len(nodelist)**0.5,\n",
    "                          iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "visualize_embedding(siamese, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"RNA Type\", # sc.tolist(), \n",
    "                    node_pos=layout,\n",
    "                    top_k=0,\n",
    "                    edgelist=edgelist,\n",
    "                    edge_color=edge_colors, edge_cmap=plt.cm.Blues,\n",
    "#                     test_nodes=siamese.generator_val.get_nonzero_nodelist(),\n",
    "                    cmap=\"viridis\",\n",
    "                    figsize=(8, 8), dpi=150,\n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=6,\n",
    "                    node_size=\"centrality\", \n",
    "#                     file_name=\"moge/data/Results/vis_lncRNAs/{}\".format(center_node),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize RNA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(rna2rna_emb, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"locus_type\", # sc.tolist(), \n",
    "                    top_k=0,\n",
    "                    edgelist=network.get_edgelist(node_list=nodelist, inclusive=True),\n",
    "#                     test_nodes=siamese.generator_val.get_nonzero_nodelist(),\n",
    "                    cmap=\"gist_ncar\",\n",
    "                    node_size=\"centrality\", \n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=9,\n",
    "                    figsize=(10,10), dpi=150,\n",
    "#                     file_name=\"moge/data/Results/siamese_online_triplet_euclidean\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.process_embeddings(variable_length=True, minlen=200)\n",
    "# delattr(siamese, \"node_pos\")\n",
    "visualize_embedding(siamese, network=network, node_label=\"locus_type\", \n",
    "#                     edgelist=network_val.get_edgelist(node_list=nodes_to_visualize, \n",
    "#                                                       edge_types=[\"d\"])[:500],\n",
    "#                     test_nodes=nodes_test,\n",
    "                    cmap=\"gist_ncar\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(network.G.subgraph(nodelist), \"./moge/data/Networks/{}.edgelist\".format(center_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bokeh_graph(network.G.subgraph(nodelist), node_pos=layout,\n",
    "                 node_label=network.genes_info.loc[nodelist, \"locus_type\"].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
