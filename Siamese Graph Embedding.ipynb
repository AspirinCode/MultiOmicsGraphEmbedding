{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from TCGAMultiOmics.multiomics import MultiOmicsData\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n",
    "\n",
    "from moge.visualization.plot_data import matrix_heatmap, bar_chart\n",
    "from moge.network.edge_generator import DataGenerator\n",
    "from moge.visualization.visualize_embedding import visualize_embedding, plot_bokeh_graph\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moge/data/luad_data_longest.pickle', 'rb') as file:\n",
    "    luad_data = pickle.load(file)\n",
    "#     network.multi_omics_data = luad_data\n",
    "#     network_val.multi_omics_data = luad_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.heterogeneous_network import get_rename_dict\n",
    "noncode_rename_dict = pd.Series(luad_data.LNC.noncode_func_df[\"Gene Name\"].values,\n",
    "     index=luad_data.LNC.noncode_func_df[\"NONCODE Gene ID\"].str.split(\".\", expand=True)[0]).to_dict()\n",
    "noncode_rename_dict = {k: noncode_rename_dict[k] for k in noncode_rename_dict if type(noncode_rename_dict[k])!=float}\n",
    "\n",
    "lncbase_rename_dict = get_rename_dict(luad_data.LNC.get_genes_info(), \"Gene ID\")\n",
    "lncbase_rename_dict.update(noncode_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 45836\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "with open('moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.train.pickle', 'rb') as file:\n",
    "# with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.latest.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    network.preprocess_graph()\n",
    "    network.process_genes_info()\n",
    "    \n",
    "network.G.remove_edges_from([(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIR  nodes: 1870\n",
      "GE  nodes: 20157\n",
      "LNC  nodes: 12706\n",
      "Total nodes: 58986\n",
      "Genes info columns: ['Disease association', 'locus_type', 'Transcript sequence', 'Chromosome', 'GO Terms', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# READ edgelists\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test_v2.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)\n",
    "    network_val.preprocess_graph()\n",
    "    network_val.process_genes_info()\n",
    "    \n",
    "network_val.G.remove_edges_from([(u,v,d) for u,v,d in network_val.G.edges(data=True) if \"database\" in d and \\\n",
    "                             d[\"database\"]==\"NPInter\" and u in network.nodes[\"GE\"]])\n",
    "network_val.G = nx.relabel_nodes(network_val.G, lncbase_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('moge/data/luad_data_shortest.pickle', 'rb') as file:\n",
    "#     luad_data = pickle.load(file)\n",
    "#     network.multi_omics_data = luad_data\n",
    "#     network.process_genes_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     32741.000000\n",
       "mean       2670.878715\n",
       "std        2783.388100\n",
       "min          41.000000\n",
       "50%        1979.000000\n",
       "75%        3780.000000\n",
       "85%        5008.000000\n",
       "90%        5928.000000\n",
       "95%        7686.000000\n",
       "99%       12322.600000\n",
       "max      109224.000000\n",
       "Name: Transcript length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.genes_info[\"Transcript length\"] = network.genes_info[\"Transcript sequence\"].apply(lambda x: len(x) if type(x) == str else None)\n",
    "network.genes_info[\"Transcript length\"].describe(percentiles=[.50, .75, .85, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"d\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_heatmap(network.get_adjacency_matrix(edge_types=[\"u_n\"], node_list=network.node_list).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test data to recall\n",
    "# matrix_heatmap(network_val.get_adjacency_matrix(edge_types=[\"d\"], node_list=network_val.node_list).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'weighted': True,\n",
    " 'undirected_distance': 'euclidean',\n",
    " 'truncating': 'post',\n",
    " 'source_target_dense_layers': True,\n",
    " 'negative_sampling_ratio': 5.0,\n",
    " 'max_length': 5050,\n",
    " 'max2_pool_size': 6,\n",
    " 'max1_pool_size': 9,\n",
    " 'margin': 0.5,\n",
    " 'lstm_unit_size': 320,\n",
    " 'lr': 0.0005,\n",
    " 'embedding_normalization': True,\n",
    " 'directed_proba': 1.0,\n",
    " 'directed_distance': 'euclidean',\n",
    " 'dense2_unit_size': 512,\n",
    " 'dense1_unit_size': None,\n",
    " 'd': 128,\n",
    " 'conv2_kernel_size': 6,\n",
    " 'conv2_batch_norm': True,\n",
    " 'conv1_kernel_size': 6,\n",
    " 'conv1_batch_norm': True,\n",
    " 'compression_func': 'sqrt3'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directed_margin 0.5 , undirected_margin 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseOnlineTripletGraphEmbedding(batch_size=225, compression_func='sqrt3',\n",
       "                  conv1_batch_norm=True, conv1_kernel_size=6,\n",
       "                  conv2_batch_norm=True, conv2_kernel_size=6, d=128,\n",
       "                  dense1_unit_size=None, dense2_unit_size=512,\n",
       "                  directed_distance='euclidean', directed_proba=1.0,\n",
       "                  embedding_normalization=True, epochs=200, lr=0.0005,\n",
       "                  lstm_unit_size=320, margin=0.5, max1_pool_size=9,\n",
       "                  max2_pool_size=6, max_length=5050,\n",
       "                  negative_sampling_ratio=5.0, seed=0,\n",
       "                  source_target_dense_layers=True, truncating='post',\n",
       "                  undirected_distance='euclidean', verbose=True,\n",
       "                  weighted=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moge.embedding.siamese_graph_embedding import SiameseGraphEmbedding\n",
    "from moge.embedding.siamese_triplet_online_embedding import SiameseOnlineTripletGraphEmbedding\n",
    "\n",
    "siamese = SiameseOnlineTripletGraphEmbedding(batch_size=225, margin=params[\"margin\"], epochs=200, verbose=True)\n",
    "# siamese = SiameseGraphEmbedding(batch_size=500, epochs=10, verbose=True)\n",
    "\n",
    "# siamese = SiameseTripletGraphEmbedding(d=128, batch_size=256, margin=0.2, lr=0.001, epochs=30, \n",
    "#     negative_sampling_ratio=2.0, directed_proba=0.8, compression_func=\"sqrt3\",\n",
    "#     max_length=2000, truncating=\"post\", verbose=True)\n",
    "\n",
    "siamese.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# with open(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/params.txt\", \"r\") as file:\n",
    "#     params = yaml.load(str(file.read()))\n",
    "#     params[\"subsample\"] = False\n",
    "#     siamese.set_params(**params)\n",
    "#     file.close()\n",
    "    \n",
    "# siamese.load_model(\"logs/SiameseGraphEmbeddin_03-29_11-50PM/lstm_model.e5.h5\", network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index: {'A': 1, 'T': 2, 'G': 3, 'C': 4}\n",
      "# of nodes to sample from (non-zero degree): 31699\n",
      "# of nodes to sample from (non-zero degree): 4113\n",
      "labels_directed SparseTensor(indices=Tensor(\"labels_directed/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_directed/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_directed/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "labels_undirected SparseTensor(indices=Tensor(\"labels_undirected/indices:0\", shape=(?, 2), dtype=int64, device=/device:GPU:0), values=Tensor(\"labels_undirected/values:0\", shape=(?,), dtype=float32, device=/device:GPU:0), dense_shape=Tensor(\"labels_undirected/shape:0\", shape=(2,), dtype=int64, device=/device:GPU:0))\n",
      "Embedding Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, ?, 4), dtype=float32, device=/device:GPU:0)\n",
      "conv2D Tensor(\"lstm_lambda_2/Squeeze:0\", shape=(?, ?, 320), dtype=float32, device=/device:GPU:0)\n",
      "conv1d_2 Tensor(\"lstm_conv_2/Relu:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "max pooling_2 Tensor(\"max_pooling1d_2/Squeeze:0\", shape=(?, ?, 192), dtype=float32, device=/device:GPU:0)\n",
      "brnn Tensor(\"bidirectional_1/concat_2:0\", shape=(?, 640), dtype=float32, device=/device:GPU:0)\n",
      "source Tensor(\"lambda_1/l2_normalize:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "target Tensor(\"lambda_2/l2_normalize:0\", shape=(?, 64), dtype=float32, device=/device:GPU:0)\n",
      "embedding Tensor(\"embedding_output/concat:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "embeddings Tensor(\"lstm_network/embedding_output/concat:0\", shape=(?, 128), dtype=float32, device=/device:GPU:0)\n",
      "directed_pairwise_distances Tensor(\"directed_pairwise_distances/Maximum:0\", shape=(?, ?), dtype=float32, device=/device:GPU:0)\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "loss Tensor(\"add_4:0\", shape=(), dtype=float32, device=/device:GPU:0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-975df9cc865b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         seed=0),\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/embedding/siamese_triplet_online_embedding.py\u001b[0m in \u001b[0;36mlearn_embedding\u001b[0;34m(self, network, network_val, tensorboard, histogram_freq, early_stopping, multi_gpu, subsample, n_steps, validation_steps, edge_f, is_weighted, no_python, rebuild_model, seed, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"siamese_net\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrebuild_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhistogram_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MultiOmicsGraphEmbedding/moge/embedding/siamese_triplet_online_embedding.py\u001b[0m in \u001b[0;36mbuild_keras_model\u001b[0;34m(self, multi_gpu)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 metrics=[self.custom_recall([directed_pairwise_distances, labels_directed]),\n\u001b[0;32m--> 180\u001b[0;31m                          self.custom_precision([directed_pairwise_distances, labels_directed])],\n\u001b[0m\u001b[1;32m    181\u001b[0m                                      )\n\u001b[1;32m    182\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Network total weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \"\"\"\n\u001b[0;32m--> 671\u001b[0;31m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[1;32m    672\u001b[0m                     \u001b[0;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                     \u001b[0;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ]
    }
   ],
   "source": [
    "siamese.learn_embedding(network, network_val=network_val, \n",
    "                        multi_gpu=False, rebuild_model=True,\n",
    "                        n_steps=1000, \n",
    "                        validation_steps=250,\n",
    "                        tensorboard=True,\n",
    "                        early_stopping=10,\n",
    "                        initial_epoch=0,\n",
    "                        seed=0),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_heatmap(siamese.get_embedding(recompute=True), cmap=\"bwr\", aspect='auto', figsize=(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delattr(siamese, \"reconstructed_adj\") if hasattr(siamese, \"reconstructed_adj\") else None\n",
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"d\", \n",
    "#                                              interpolate=False,\n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(),\n",
    "                                            ), figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_heatmap(siamese.get_reconstructed_adj(edge_type=\"u\", \n",
    "#                                              node_l=siamese.generator_train.get_nonzero_nodelist(), \n",
    "                                             ), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.save_model(\"lstm_model.h5\", model=\"lstm\", logdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.truncating = \"post\"\n",
    "# siamese.save_embeddings(\"lmn_train.triplet.shortest.biogrid.full.euclidean.trunc.emb\", \n",
    "#                         variable_length=False, recompute=False, minlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.embedding.static_graph_embedding import ImportedGraphEmbedding\n",
    "from moge.embedding.sequence_based_embedding import BioVecEmbedding, iDeepVEmbedding, LncTarInteraction\n",
    "\n",
    "nodelist = network.genes_info.index.tolist()\n",
    "\n",
    "# biovec_emb = BioVecEmbedding(network, {\"MIR\": \"moge/data/biovec/miRNA_protvec.model\",\n",
    "#                          \"GE\": \"moge/data/biovec/mRNA_protvec.model\",\n",
    "#                          \"LNC\": \"moge/data/biovec/lncRNA_protvec.model\"})\n",
    "\n",
    "node2vec_emb = ImportedGraphEmbedding(d=128, method_name=\"node2vec\")\n",
    "node2vec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.node2vec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "biovec_emb = ImportedGraphEmbedding(d=100, method_name=\"BioVec\")\n",
    "biovec_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.biovec.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "line_emb = ImportedGraphEmbedding(d=128, method_name=\"LINE\")\n",
    "line_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.line.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "hope_emb = ImportedGraphEmbedding(d=128, method_name=\"HOPE\")\n",
    "hope_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.hope.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "sdne_emb = ImportedGraphEmbedding(d=128, method_name=\"SDNE\")\n",
    "sdne_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Only/lmn_train.all.sdne.emb\", \n",
    "                          node_list=nodelist)\n",
    "\n",
    "\n",
    "rna2rna_emb = ImportedGraphEmbedding(d=128, method_name=\"rna2rna\")\n",
    "rna2rna_emb.import_embedding(\"moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/lmn_train.siamese.multi_seq_UT.biogrid.full.euclidean.trunc.emb\", \n",
    "                         node_list=network.node_list)\n",
    "rna2rna_emb.network = network\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rna2rna_graph = nx.from_numpy_matrix(rna2rna_emb.get_reconstructed_adj(), create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delattr(rna2rna_emb, \"reconstructed_adj\") if hasattr(rna2rna_emb, \"reconstructed_adj\") else None\n",
    "# matrix_heatmap(rna2rna_emb.get_reconstructed_adj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {}\n",
    "methods[\"node2vec\"] = node2vec_emb\n",
    "methods[\"LINE\"] = line_emb\n",
    "methods[\"HOPE\"] = hope_emb\n",
    "methods[\"SDNE\"] = sdne_emb\n",
    "methods[\"BioVec\"] = biovec_emb\n",
    "# methods[\"rna2rna\"] = rna2rna_emb\n",
    "methods[\"rna2rna\"] = siamese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v2.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase Predicted\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 7.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.5\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v3.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = nx.isolates(network_val.G)\n",
    "network_val.G.remove_nodes_from(list(isolates))\n",
    "isolates = nx.isolates(network.G)\n",
    "network.G.remove_nodes_from(list(isolates))\n",
    "novel_nodes = list(set(network_val.G.nodes()) - set(network.G.nodes()))\n",
    "print(len(novel_nodes), {modality:len(set(novel_nodes) & set(network.nodes[modality])) for modality in [\"LNC\", \"MIR\", \"GE\"]})\n",
    "novel_edges = list(network_val.G.edges(novel_nodes, data=True))\n",
    "print(len(novel_edges))\n",
    "network_val.G.clear()\n",
    "network_val.G.add_edges_from(novel_edges)\n",
    "\n",
    "generator_val_novel = DataGenerator(network=network_val, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1,\n",
    "                             training_network=network)\n",
    "generator_val_novel.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pr_curve_link_pred_by_database(methods, generator_val_novel, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "#                                             (\"LNC\", \"GE\", \"lncRInter\"),\n",
    "#                                             (\"LNC\", \"GE\", \"LncReg\"),\n",
    "                                              ])\n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_lncbase_mirtarbase_biogrid_npinter_lncrna2target.test_v2.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training set (for graph reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.edge_generator import DataGenerator\n",
    "\n",
    "generator_train = DataGenerator(network=network, \n",
    "                             negative_sampling_ratio=1.0,\n",
    "                             batch_size=1,\n",
    "#                              maxlen=siamese.max_length,\n",
    "                             truncating=\"post\",\n",
    "                             shuffle=True, seed=1)\n",
    "generator_train.Eu_count = 0\n",
    "generator_train.En_count = 0\n",
    "generator_train.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_pr_curve_link_pred, evaluate_pr_curve_link_pred_by_database\n",
    "# evaluate_pr_curve_link_pred(methods, X, y_true)\n",
    "evaluate_pr_curve_link_pred_by_database(methods, generator_train, \n",
    "                                        tests=[\n",
    "                                            (\"LNC\", \"GE\", \"lncrna2target\", \"LncRNA2Target v1.0\"),\n",
    "                                            (\"MIR\", \"LNC\", \"lncBase\", \"lncBase v2\"),\n",
    "                                            (\"MIR\", \"GE\", \"miRTarBase\", \"miRTarBase 6.0\"), \n",
    "                                            (\"GE\", \"GE\", \"BioGRID\", \"BioGRID v3.4\"), \n",
    "                                            (None, None, \"NPInter\", \"NPInter v2.0 \"),\n",
    "                                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.link_prediction import evaluate_top_k_link_pred\n",
    "\n",
    "database_tests = [\n",
    "    (\"LNC\", \"GE\", \"lncrna2target\"),\n",
    "    (\"MIR\", \"LNC\", \"lncBase\"),\n",
    "    (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "    (\"GE\", \"GE\", \"BioGRID\"), \n",
    "    (\"LNC\", \"MIR\", \"lncRInter\"),\n",
    "    # (\"LNC\", \"GE\", \"LncReg\"),\n",
    "]\n",
    "top_k = 10000\n",
    "\n",
    "for source, target, database in database_tests:\n",
    "    print(database)\n",
    "    results = {}\n",
    "    for method in methods.keys():\n",
    "        results[method] = \\\n",
    "              evaluate_top_k_link_pred(methods[method], network_train=network, network_test=network_val, \n",
    "                                       node_list=network.nodes[source], node_list_B=network.nodes[target], \n",
    "                                       edge_type=\"d\", databases=[database], top_k=top_k)\n",
    "        \n",
    "    bar_chart(results, measures=['precision', 'recall'], \n",
    "              title=\"Top-k (k={}) Predictions on {}\".format(top_k, database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"locus_type\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "\n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'],\n",
    "         title=\"Clustering Evaluation to {}\".format(\"RNA Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.node_clustering import evaluate_clustering\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    results[method] = evaluate_clustering(methods[method], network=network, node_label=\"Family\", \n",
    "                                          max_clusters=500, n_clusters=None)\n",
    "    \n",
    "bar_chart(results, measures=['homogeneity', 'completeness', 'nmi'], \n",
    "          title=\"Clustering Evaluation to {}\".format(\"RNA Family\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Family\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.evaluation.node_classification import evaluate_classification\n",
    "\n",
    "results = {}\n",
    "for method in methods.keys():\n",
    "    result = {k: np.average(v) for k,v in evaluate_classification(methods[method], network, cv=10,\n",
    "                                  node_label=\"Disease association\", multilabel=True,\n",
    "                                  scoring=['precision_macro', 'recall_macro', \"f1_macro\"],\n",
    "                                                                verbose=True).items()}\n",
    "    results[method] = result\n",
    "    \n",
    "bar_chart(results, measures=['test_precision_macro', 'test_recall_macro', 'test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moge.evaluation.utils import get_scalefree_fit_score\n",
    "\n",
    "results = {}\n",
    "modalities = [(\"MIR\", \"LNC\"), (\"LNC\", \"MIR\"), (\"LNC\", \"GE\"), (\"MIR\", \"GE\"), (\"GE\", \"GE\")]\n",
    "labels = [\"miRNA-lncRNA\", \"lncRNA-miRNA\", \"lncRNA-mRNA\", \"miRNA-mRNA\", \"mRNA-mRNA\"]\n",
    "databases = [\"lncBase\", \"NPInter\", \"lncrna2target\", \"miRTarBase\", \"BioGRID\"]\n",
    "\n",
    "for method in [\"Databases\"]+list(methods.keys()):\n",
    "    if method == \"BioVec\":\n",
    "        continue\n",
    "    elif method == \"Databases\":\n",
    "        sub_result = {}\n",
    "        for (A, B), label, database in zip(modalities, labels, databases):\n",
    "            adj = network.get_adjacency_matrix(edge_types=[\"d\"], \n",
    "                                               node_list=network.node_list,\n",
    "                                               databases=[database,])\n",
    "            network_degrees = np.sum(adj, axis=1)\n",
    "            sub_result[label] = get_scalefree_fit_score(network_degrees, plot=False)\n",
    "        results[method] = sub_result\n",
    "    else:\n",
    "        sub_result = {}\n",
    "        for (A, B), label in zip(modalities, labels):\n",
    "           sub_result[label] = methods[method].get_scalefree_fit_score(network.nodes[A], network.nodes[B])\n",
    "        results[method] = sub_result\n",
    "    \n",
    "bar_chart(results, measures=labels, title=\"Scale-free fit scores\", loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = [(\"MIR\", \"LNC\", \"lncBase\"), \n",
    "              (\"LNC\", \"MIR\", \"NPInter\"), \n",
    "              (\"LNC\", \"GE\", \"lncrna2target\"), \n",
    "              (\"MIR\", \"GE\", \"miRTarBase\"), \n",
    "              (\"GE\", \"GE\", \"BioGRID\")\n",
    "             ]\n",
    "\n",
    "nodes_inters_dict = {}\n",
    "for A, B, database in modalities:\n",
    "    edge_list = [(u,v,d) for u,v,d in network.G.edges(data=True) if \"database\" in d and d[\"database\"]==database and\\\n",
    "                u in network.nodes[A] and v in network.nodes[B]]\n",
    "    nodes_inters_dict[(A, B)] = {}\n",
    "    nodes_inters_dict[(A, B)][A] = {u for u,v,d in edge_list}\n",
    "    nodes_inters_dict[(A, B)][B] = {v for u,v,d in edge_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_inters_dict_2 = dict.fromkeys(rna2rna_emb.node_list, 0)\n",
    "\n",
    "for A, B, database in modalities:\n",
    "    if database == \"BioGRID\": continue\n",
    "    for node in nodes_inters_dict[(A, B)][A]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "    for node in nodes_inters_dict[(A, B)][B]:\n",
    "        if node in nodes_inters_dict_2:\n",
    "            nodes_inters_dict_2[node] = nodes_inters_dict_2[node] + 1\n",
    "        \n",
    "trimodule_nodes = [k for k,v in nodes_inters_dict_2.items() if (k in network.nodes[\"LNC\"] and v >= 2) or \\\n",
    "                   (k in network.nodes[\"MIR\"] and v >= 2) or \\\n",
    "                  (k in network.nodes[\"GE\"] and v >= 2)]\n",
    "[(m, len(set(trimodule_nodes) & set(network.nodes[m]))) for m in [\"LNC\", \"MIR\", \"GE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(trimodule_nodes) & set(network.nodes[\"LNC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = network.G.subgraph(trimodule_nodes).to_undirected()\n",
    "center_node = \"XIST\"\n",
    "nodelist = list(g.neighbors(center_node))+[center_node]\n",
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_edges = siamese.get_top_k_predicted_edges(edge_type=\"d\", top_k=50, \n",
    "                                  node_list=network.nodes[\"MIR\"] + network.nodes[\"LNC\"],\n",
    "#                                                     , node_list_B=network.nodes[\"MIR\"],\n",
    "                                  training_network=network,)\n",
    "predicted_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = nx.spring_layout(network.G.subgraph(nodelist), \n",
    "#                           weight='weight',\n",
    "                          k=15.0/len(nodelist)**0.5,\n",
    "                          iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(rna2rna_emb, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"RNA Type\", # sc.tolist(), \n",
    "                    node_pos=layout,\n",
    "                    top_k=0,\n",
    "                    edgelist=network.get_edgelist(node_list=nodelist, inclusive=True),\n",
    "#                     test_nodes=siamese.generator_val.get_nonzero_nodelist(),\n",
    "                    cmap=\"viridis\",\n",
    "                    figsize=(8, 8), dpi=150,\n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=6,\n",
    "                    node_size=\"centrality\", \n",
    "                    file_name=\"moge/data/Results/vis_lncRNAs/{}\".format(center_node),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(rna2rna_emb, network=network, \n",
    "                    nodelist=nodelist,\n",
    "                    node_label=\"locus_type\", # sc.tolist(), \n",
    "                    top_k=0,\n",
    "                    edgelist=network.get_edgelist(node_list=nodelist, inclusive=True),\n",
    "#                     test_nodes=siamese.generator_val.get_nonzero_nodelist(),\n",
    "                    cmap=\"gist_ncar\",\n",
    "                    node_size=\"centrality\", \n",
    "                    with_labels=True, font_size=0, labels=None, arrowsize=9,\n",
    "                    figsize=(10,10), dpi=150,\n",
    "#                     file_name=\"moge/data/Results/siamese_online_triplet_euclidean\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.process_embeddings(variable_length=True, minlen=200)\n",
    "# delattr(siamese, \"node_pos\")\n",
    "visualize_embedding(siamese, network=network, node_label=\"locus_type\", \n",
    "#                     edgelist=network_val.get_edgelist(node_list=nodes_to_visualize, \n",
    "#                                                       edge_types=[\"d\"])[:500],\n",
    "#                     test_nodes=nodes_test,\n",
    "                    cmap=\"gist_ncar\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(network.G.subgraph(nodelist), \"./moge/data/Networks/{}.edgelist\".format(center_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bokeh_graph(network.G.subgraph(nodelist), node_pos=layout,\n",
    "                 node_label=network.genes_info.loc[nodelist, \"locus_type\"].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
