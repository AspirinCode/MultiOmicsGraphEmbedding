{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\\\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "from TCGAMultiOmics.multiomics import MultiOmicsData\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# WRITE\n",
    "# with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0.pickle', 'wb') as file:\n",
    "#     pickle.dump(network, file)\n",
    "\n",
    "# READ\n",
    "with open('moge/data/lncRNA_miRNA_mRNA/lncRNA-miRNA-mRNA_network_new.pickle', 'rb') as file:\n",
    "# with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_biogrid.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "#     network.remove_extra_nodes()\n",
    "#     network.node_list = network.all_nodes\n",
    "#     node_list = network.node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v,d in network.G.edges(data=True):\n",
    "    if d[\"type\"] == 'u_n':\n",
    "        d['weight']+=1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ edgelists\n",
    "with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0_test_edges.pickle', 'rb') as file:\n",
    "    test_edges_dict = pickle.load(file)\n",
    "    \n",
    "with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0_val_edges.pickle', 'rb') as file:\n",
    "    val_edges_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = network.multi_omics_data.load_data(modalities=[\"MIR\", \"GE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.multi_omics_data.external_data_path = \"/home/jonny/PycharmProjects/Bioinformatics_ExternalData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1870)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X[\"MIR\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Source Target Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Lambda, Dot, Dense, Flatten, MaxPooling1D, Lambda\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = np.random.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=np.random.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonny/.conda/envs/jonny_conda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "# sess.close()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features_size = X[\"MIR\"].shape[0]\n",
    "input_shape = (None, 4)\n",
    "_d = 128\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('inputs'):\n",
    "E_ij = Input(batch_shape=(batch_size, 1), name=\"E_ij\")\n",
    "#     input_i = tf.placeholder(tf.float32, shape=input_shape, name=\"input_i\")\n",
    "#     input_j = tf.placeholder(tf.float32, shape=input_shape, name=\"input_j\")\n",
    "input_seq_i = Input(batch_shape=(batch_size, None, 4), name=\"input_seq_i\")\n",
    "input_seq_j = Input(batch_shape=(batch_size, None, 4), name=\"input_seq_j\")\n",
    "# is_directed = tf.placeholder(tf.bool, name=\"is_directed\")\n",
    "is_directed = Input(batch_shape=(batch_size, 1), dtype=tf.bool, name=\"is_directed\")\n",
    "# i = tf.Variable(int, name=\"i\", trainable=False)\n",
    "# j = tf.Variable(int, name=\"j\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    \"\"\" Base network to be shared (eq. to feature extraction).\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "#     x = Flatten()(input)\n",
    "    x = LSTM(128, input_shape=input_shape, return_sequences=False)(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def source_target_emebedding_distance(vects):\n",
    "    emb_i, emb_j, is_directed = vects\n",
    "    dot_directed = Dot(axes=1)([emb_i[:, 0:int(_d/2)], emb_j[:, int(_d/2):_d]])\n",
    "    dot_undirected = Dot(axes=1)([emb_i, emb_j])\n",
    "    return K.switch(is_directed, K.sigmoid(dot_directed), K.sigmoid(dot_undirected))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_network <keras.engine.training.Model object at 0x7fc2fe43ff98>\n",
      "encoded_i Tensor(\"model_1/dense_3/Relu:0\", shape=(1, 128), dtype=float32) \n",
      "encoded_j Tensor(\"model_1_1/dense_3/Relu:0\", shape=(1, 128), dtype=float32)\n",
      "distance Tensor(\"lambda_1/Select_1:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build create_base_network to use in each siamese 'leg'\n",
    "lstm_network = create_base_network(input_shape=(None, 4))\n",
    "\n",
    "print(\"lstm_network\", lstm_network)\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_i = lstm_network(input_seq_i)\n",
    "encoded_j = lstm_network(input_seq_j)\n",
    "print(\"encoded_i\", encoded_i, \"\\nencoded_j\", encoded_j)\n",
    "\n",
    "distance = Lambda(source_target_emebedding_distance)([encoded_i, encoded_j, is_directed])\n",
    "print(\"distance\", distance)\n",
    "\n",
    "siamese_net = Model(inputs=[input_seq_i, input_seq_j, is_directed], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117632"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=contrastive_loss, \n",
    "                    optimizer=RMSprop(lr=0.01),\n",
    "                    metrics=[accuracy])\n",
    "\n",
    "siamese_net.count_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ed_count 448908 Eu_count 2550360 En_count 2307016\n"
     ]
    }
   ],
   "source": [
    "generator = DataGenerator(network.node_list, network=network, \n",
    "                          batch_size=1, dim=(None, 4), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGAAAACTTCCTGAGGCCTCCTCAGAAGCAGATGCTGCTATGCTTCCCGTACAGCCTGAAGAACCAAACATTTCTATACATTTATGAGACCCAACTCCAAAAGCATACTGGAATGGAATTAAAGACCGAACTACAGAAGCTAAAGAGAGCTGATCAAACTAAAAAAAAAAGTTAAAGGTGAGGAGGCCAAGGCTCAGAAGAGTCACTTGCCCATGATCACTGCTCTTATAGCGCCAACTCAGAGCTCAGGCAATGCTCATGTTCTTTCCACTGTGCCTCATCGCTCATGTCTGACTCTTCTAGAAATGTGGGCAAATCCCCTGCCTTCTGTGGGTCTCAGATTTCCATAAAAAATAAAATCAATGGATCAACTTAA'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.multi_omics_data.LNC.get_genes_info().iloc[2][\"Transcript sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2595, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"input_seq_i\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 µs ± 1.26 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generator.seq_to_array(_34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "    877/5306284 [..............................] - ETA: 1568:13:57 - loss: 0.7648 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "siamese_net.fit_generator(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
