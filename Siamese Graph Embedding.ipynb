{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\\\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "from TCGAMultiOmics.multiomics import MultiOmicsData\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# WRITE\n",
    "# with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0.pickle', 'wb') as file:\n",
    "#     pickle.dump(network, file)\n",
    "\n",
    "# READ\n",
    "# with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0.pickle', 'rb') as file:\n",
    "with open('/Users/jonny/Desktop/PycharmProjects/MultiOmicsGraphEmbedding/data/miRNA-mRNA_network.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    network.remove_extra_nodes()\n",
    "#     network.node_list = network.all_nodes\n",
    "#     node_list = network.node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ edgelists\n",
    "with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0_test_edges.pickle', 'rb') as file:\n",
    "    test_edges_dict = pickle.load(file)\n",
    "    \n",
    "with open('moge/data/lncRNA_miRNA_mRNA/miRNA-mRNA_network_test_05_val_01_seed_0_val_edges.pickle', 'rb') as file:\n",
    "    val_edges_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = network.multi_omics_data.load_data(modalities=[\"MIR\", \"GE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1870)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"MIR\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonny/anaconda3/lib/python3.6/site-packages/TCGAMultiOmics/genomic.py:549: FutureWarning: 'MiRBase ID' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  gene_info = gene_info.join(self.targetScan_family_df.groupby(\"MiRBase ID\").first(), on=\"MiRBase ID\",how=\"left\")\n"
     ]
    }
   ],
   "source": [
    "transcripts = network.multi_omics_data.MIR.get_genes_info()[\"Mature sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1617.000000\n",
       "mean       21.403834\n",
       "std         1.644691\n",
       "min        16.000000\n",
       "25%        21.000000\n",
       "50%        22.000000\n",
       "75%        22.000000\n",
       "max        27.000000\n",
       "Name: Mature sequence, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[transcripts.notna()].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiRBase ID\n",
       "hsa-let-7a-1                            NaN\n",
       "hsa-let-7a-2         CUGUACAGCCUCCUAGCUUUCC\n",
       "hsa-let-7a-3                            NaN\n",
       "hsa-let-7b           UGAGGUAGUAGGUUGUGUGGUU\n",
       "hsa-let-7c           UGAGGUAGUAGGUUGUAUGGUU\n",
       "hsa-let-7d           AGAGGUAGUAGGUUGCAUAGUU\n",
       "hsa-let-7e           UGAGGUAGGAGGUUGUAUAGUU\n",
       "hsa-let-7f-1         CUAUACAAUCUAUUGCCUUCCC\n",
       "hsa-let-7f-2         CUAUACAGUCUACUGUCUUUCC\n",
       "hsa-let-7g           UGAGGUAGUAGUUUGUACAGUU\n",
       "hsa-let-7i           UGAGGUAGUAGUUUGUGCUGUU\n",
       "hsa-mir-1-1                             NaN\n",
       "hsa-mir-1-2                             NaN\n",
       "hsa-mir-100          CAAGCUUGUAUCUAUAGGUAUG\n",
       "hsa-mir-101-1                           NaN\n",
       "hsa-mir-101-2                           NaN\n",
       "hsa-mir-103a-1                          NaN\n",
       "hsa-mir-103a-2      AGCUUCUUUACAGUGCUGCCUUG\n",
       "hsa-mir-103b-1                          NaN\n",
       "hsa-mir-103b-2                          NaN\n",
       "hsa-mir-105-1                           NaN\n",
       "hsa-mir-105-2                           NaN\n",
       "hsa-mir-106a         CUGCAAUGUAAGCACUUCUUAC\n",
       "hsa-mir-106b         CCGCACUGUGGGUACUUGCUGC\n",
       "hsa-mir-107         AGCAGCAUUGUACAGGGCUAUCA\n",
       "hsa-mir-10a         UACCCUGUAGAUCCGAAUUUGUG\n",
       "hsa-mir-10b         UACCCUGUAGAACCGAAUUUGUG\n",
       "hsa-mir-1178          UUGCUCACUGUUCUUCCCUAG\n",
       "hsa-mir-1179          AAGCAUUCUUUCAUUGGUUGG\n",
       "hsa-mir-1180         UUUCCGGCUCGCGUGGGUGUGU\n",
       "                            ...            \n",
       "hsa-mir-9-2                             NaN\n",
       "hsa-mir-9-3                             NaN\n",
       "hsa-mir-920            GGGGAGCUGUGGAAGCAGUA\n",
       "hsa-mir-921       CUAGUGAGGGACAGAACCAGGAUUC\n",
       "hsa-mir-922         GCAGCAGAGAAUAGGACUACGUC\n",
       "hsa-mir-924            AGAGUCUUGUGAUGUCUUGC\n",
       "hsa-mir-92a-1       AGGUUGGGAUCGGUUGCAAUGCU\n",
       "hsa-mir-92a-2        GGGUGGGGAUUUGUUGCAUUAC\n",
       "hsa-mir-92b          UAUUGCACUCGUCCCGGCCUCC\n",
       "hsa-mir-93          CAAAGUGCUGUUCGUGCAGGUAG\n",
       "hsa-mir-933          UGUGCGCAGGGAGACCUCUCCC\n",
       "hsa-mir-934          UGUCUACUACUGGAGACACUGG\n",
       "hsa-mir-935         CCAGUUACCGCUUCCGCUACCGC\n",
       "hsa-mir-936          ACAGUAGAGGGAGGAAUCGCAG\n",
       "hsa-mir-937          AUCCGCGCUCUGACUCUCUGCC\n",
       "hsa-mir-938          UGCCCUUAAAGGUGAACCCAGU\n",
       "hsa-mir-939           CCCUGGGCCUCUGCUCCCCAG\n",
       "hsa-mir-940           AAGGCAGGGCCCCCGCUCCCC\n",
       "hsa-mir-941-1                           NaN\n",
       "hsa-mir-941-2                           NaN\n",
       "hsa-mir-941-3                           NaN\n",
       "hsa-mir-941-4                           NaN\n",
       "hsa-mir-942          CACAUGGCCGAAACAGAGAAGU\n",
       "hsa-mir-943           CUGACUGUUGCCGUCCUCCAG\n",
       "hsa-mir-944          AAAUUAUUGUACAUCGGAUGAG\n",
       "hsa-mir-95           UUCAACGGGUAUUUAUUGAGCA\n",
       "hsa-mir-96           AAUCAUGUGCAGUGCCAAUAUG\n",
       "hsa-mir-98           UGAGGUAGUAAGUUGUAUUGUU\n",
       "hsa-mir-99a          CAAGCUCGCUUCUAUGGGUCUG\n",
       "hsa-mir-99b          CAAGCUCGUGUCUGUGGGUCCG\n",
       "Name: Mature sequence, Length: 1870, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Source Target Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Lambda, Dot, Dense, Flatten, MaxPooling1D, Lambda\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = np.random.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=np.random.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonny/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "sess.close()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features_size = X[\"MIR\"].shape[0]\n",
    "input_shape = (None, 4)\n",
    "_d = 128\n",
    "# n_nodes = len(network.node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('inputs'):\n",
    "E_ij = Input(batch_shape=(1, ), name=\"E_ij\")\n",
    "#     input_i = tf.placeholder(tf.float32, shape=input_shape, name=\"input_i\")\n",
    "#     input_j = tf.placeholder(tf.float32, shape=input_shape, name=\"input_j\")\n",
    "input_seq_i = Input(batch_shape=(1, None, 4), name=\"input_i\")\n",
    "input_seq_j = Input(batch_shape=(1, None, 4), name=\"input_j\")\n",
    "# is_directed = tf.placeholder(tf.bool, name=\"is_directed\")\n",
    "is_directed = Input(batch_shape=(1, ), dtype=tf.bool, name=\"is_directed\")\n",
    "i = tf.Variable(int, name=\"i\", trainable=False)\n",
    "j = tf.Variable(int, name=\"j\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_i Tensor(\"sequential_6/dense_6/Sigmoid:0\", shape=(1, 128), dtype=float32) \n",
      "encoded_j Tensor(\"sequential_6_1/dense_6/Sigmoid:0\", shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build convnet to use in each siamese 'leg'\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(128, input_shape=(None, 4), return_sequences=False))\n",
    "lstm.add(Dense(_d, activation='sigmoid'))\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_i = lstm(input_seq_i)\n",
    "encoded_j = lstm(input_seq_j)\n",
    "print(\"encoded_i\", encoded_i, \"\\nencoded_j\", encoded_j)\n",
    "\n",
    "\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "# L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "# #call this layer on list of two input tensors.\n",
    "# L1_distance = L1_layer([encoded_i, encoded_j])\n",
    "# prediction = Dense(1, activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "\n",
    "\n",
    "# # output = Lambda(lambda tup: \n",
    "# #                 is_directed*tup[0] + (1-is_directed)*tup[1])([output_directed, output_undirected])\n",
    "# conditional_layer = Lambda(lambda x: K.switch(x[0], K.sigmoid(x[1]), K.sigmoid(x[2])))\n",
    "# conditional_output = conditional_layer([is_directed, dot_directed, dot_undirected])\n",
    "# print(\"conditional_output\", conditional_output)\n",
    "\n",
    "siamese_net = Model(inputs=[input_seq_i, input_seq_j, is_directed], outputs=[encoded_i, encoded_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(encoded_i, encoded_j, E_ij, is_directed):\n",
    "    dot_directed = Dot(axes=1)([encoded_i[:, 0:int(_d/2)], encoded_j[:, int(_d/2):_d]])\n",
    "    dot_undirected = Dot(axes=1)([encoded_i, encoded_j])\n",
    "    print(\"E_ij\", E_ij, \"is_directed\", is_directed)\n",
    "    print(dot_directed, dot_undirected)\n",
    "    \n",
    "    distance = -K.log(K.switch(is_directed, K.sigmoid(dot_directed), K.sigmoid(dot_undirected)))\n",
    "    \n",
    "    print(distance)\n",
    "\n",
    "    loss = (1-E_ij)*1/2*K.square(distance) + E_ij*1/2*K.square(K.maximum(0.0, 0.5 - distance))\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_ij Tensor(\"E_ij_5:0\", shape=(1,), dtype=float32) is_directed Tensor(\"is_directed_5:0\", shape=(1,), dtype=bool)\n",
      "Tensor(\"dot_23/ExpandDims:0\", shape=(1, 1), dtype=float32) Tensor(\"dot_24/ExpandDims:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"Neg_10:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"add_10:0\", shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a349be6b7f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m siamese_net.compile(loss=contrastive_loss(encoded_i, encoded_j, E_ij, is_directed), \n\u001b[0;32m----> 3\u001b[0;31m                     optimizer=Adam(0.00006))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[1;32m    666\u001b[0m                     \u001b[0;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                     \u001b[0;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ]
    }
   ],
   "source": [
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=contrastive_loss(encoded_i, encoded_j, E_ij, is_directed), \n",
    "                    optimizer=Adam(0.00006))\n",
    "\n",
    "siamese_net.count_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moge.network.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-d7faf3653a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m generator = DataGenerator(network.node_list, labels=network.node_list, network=network, \n\u001b[0;32m----> 2\u001b[0;31m                           batch_size=1, dim=(None, 4), shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/PycharmProjects/MultiOmicsGraphEmbedding/moge/network/data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, list_IDs, labels, network, get_training_data, batch_size, dim, negative_samples, shuffle)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mEd_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEd_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         Eu_rows, Eu_cols = triu(self.adj_undirected,\n\u001b[0;32m---> 28\u001b[0;31m                                 k=1).nonzero()  # only get non-zero edges from upper triangle of the adjacency matrix\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mEu_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEu_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/linalg/special_matrices.py\u001b[0m in \u001b[0;36mtriu\u001b[0;34m(m, k)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m    138\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "generator = DataGenerator(network.node_list, network=network, \n",
    "                          batch_size=1, dim=(None, 4), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 88, 4) (1, 88, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(train_generator())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    while True:\n",
    "        sequence_length = np.random.randint(10, 100)\n",
    "        x_train = np.random.random((1, sequence_length, 4))\n",
    "        # y_train will depend on past 5 timesteps of x\n",
    "        y_train = x_train[:, :, 0]\n",
    "        for i in range(1, 2):\n",
    "            y_train[:, i:] += x_train[:, :-i, i]\n",
    "        y_train = to_categorical(y_train > 2.5)\n",
    "        yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('siamese'):\n",
    "    siamese = Dense(128, activation='relu')(N_i)\n",
    "    siamese = Dense(_d, activation='relu')(siamese)\n",
    "    \n",
    "    emb_c_i = siamese(N_i)\n",
    "    emb_c_i = siamese(N_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('embedding'):\n",
    "    emb_s = tf.Variable(initial_value=tf.random_uniform([n_nodes, int(_d/2)], -1, 1),\n",
    "                        validate_shape=True, dtype=tf.float32,\n",
    "                        name=\"emb_t\", trainable=True)\n",
    "\n",
    "    emb_t = tf.Variable(initial_value=tf.random_uniform([n_nodes, int(_d/2)], -1, 1),\n",
    "                        validate_shape=True, dtype=tf.float32,\n",
    "                        name=\"emb_s\", trainable=True)\n",
    "\n",
    "    emb_c = tf.concat([emb_s, emb_t], axis=1, name=\"emb_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_s = emb_s[i].assign(tf.reshape(siamese[:, 0 : int(_d/2)], [-1]))\n",
    "emb_t = emb_t[i].assign(tf.reshape(siamese[:, int(_d/2) : _d], [-1]))\n",
    "\n",
    "# with tf.control_dependencies([emb_s[i].assign(emb_c_i)]):\n",
    "#     emb_s = tf.identity(emb_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.as_default()\n",
    "K.set_session(sess)\n",
    "session.run(init_op)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
