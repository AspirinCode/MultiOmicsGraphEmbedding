{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# READ\n",
    "with open('moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/LMN_mirtarbase_biogrid_starbase_lncrna2target_lncrinter.train.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    \n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_mirtarbase_biogrid_starbase_lncrna2target_lncrinter.test.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import uniform\n",
    "parameters = {\n",
    "    \"d\": [128, 256, 512],\n",
    "    \"lr\": [0.001, 0.0005],\n",
    "    # \"margin\": [0.1, 0.2, 0.5],\n",
    "    \"compression_func\": [\"sqrt\", \"log\", \"sqrt3\"],\n",
    "    \"negative_sampling_ratio\": [2.0, 5.0, 15.0],\n",
    "#     \"directed_proba\": [0.5, 0.8],\n",
    "    \"max_length\": [1400, 1800, 2000],\n",
    "    \"truncating\": [\"random\", \"post\"],\n",
    "    \n",
    "    \"conv1_kernel_size\": [6, 12, 18],\n",
    "    \"max1_pool_size\": [3, 4, 6],\n",
    "    \"conv2_kernel_size\": [None, 2, 4, 6],\n",
    "    \"max2_pool_size\": [2, 4, 6],\n",
    "    \"lstm_unit_size\": [160, 320],\n",
    "    \"dense1_unit_size\": [256, 512, 1024],\n",
    "    \"dense2_unit_size\": [None, 256, 512],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from moge.embedding.siamese_graph_embedding import SiameseGraphEmbedding\n",
    "from moge.embedding.siamese_triplet_online_embedding import SiameseOnlineTripletGraphEmbedding\n",
    "\n",
    "\n",
    "siamese = SiameseOnlineTripletGraphEmbedding(batch_size=386, epochs=1, verbose=False)\n",
    "\n",
    "# siamese = SiameseTripletGraphEmbedding(batch_size=256, epochs=1, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : {'truncating': 'post', 'negative_sampling_ratio': 5.0, 'max_length': 1400, 'max2_pool_size': 2, 'max1_pool_size': 3, 'lstm_unit_size': 320, 'lr': 0.001, 'dense2_unit_size': 256, 'dense1_unit_size': 1024, 'd': 128, 'conv2_kernel_size': 6, 'conv1_kernel_size': 18, 'compression_func': 'sqrt'}\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "directed_loss Tensor(\"online_triplet_loss_1/Mean_2:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "undirected_loss Tensor(\"online_triplet_loss_1/mul_10:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 867s 2s/step - loss: 0.0483 - val_loss: 0.0298\n",
      "Score: 0.02982184652239084 \n",
      "\n",
      "1 : {'truncating': 'random', 'negative_sampling_ratio': 15.0, 'max_length': 1400, 'max2_pool_size': 6, 'max1_pool_size': 4, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': None, 'dense1_unit_size': 512, 'd': 512, 'conv2_kernel_size': 2, 'conv1_kernel_size': 18, 'compression_func': 'sqrt'}\n",
      "directed_loss Tensor(\"online_triplet_loss_1/Mean_2:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "undirected_loss Tensor(\"online_triplet_loss_1/mul_10:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "Epoch 1/1\n",
      "Stop training\n",
      "2 : {'truncating': 'post', 'negative_sampling_ratio': 2.0, 'max_length': 1400, 'max2_pool_size': 4, 'max1_pool_size': 3, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': None, 'dense1_unit_size': 256, 'd': 256, 'conv2_kernel_size': None, 'conv1_kernel_size': 18, 'compression_func': 'sqrt3'}\n",
      "directed_loss Tensor(\"online_triplet_loss_1/Mean_2:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "undirected_loss Tensor(\"online_triplet_loss_1/mul_10:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-51:\n",
      "Process ForkPoolWorker-58:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training\n",
      "3 : {'truncating': 'random', 'negative_sampling_ratio': 15.0, 'max_length': 1400, 'max2_pool_size': 4, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': 512, 'dense1_unit_size': 256, 'd': 128, 'conv2_kernel_size': None, 'conv1_kernel_size': 12, 'compression_func': 'log'}\n"
     ]
    }
   ],
   "source": [
    "best_score = float(\"inf\")\n",
    "X_params = []\n",
    "y = []\n",
    "\n",
    "for g in ParameterSampler(parameters, n_iter=300):\n",
    "    print(len(X_params), \":\", g)\n",
    "    siamese.set_params(**g)\n",
    "    \n",
    "    try:\n",
    "        siamese.learn_embedding(network, network_val=network_val, multi_gpu=False, \n",
    "                            subsample=False, n_steps=500, validation_steps=None, \n",
    "                            validation_make_data=False, rebuild_model=True,\n",
    "                            seed=42)\n",
    "    except Exception as e:\n",
    "        print(\"Failed!!!\")\n",
    "        continue\n",
    "    except KeyboardInterrupt as e:\n",
    "        continue\n",
    "    \n",
    "    current_score = siamese.hist.history['val_loss'][-1]\n",
    "    X_params.append(g)\n",
    "    y.append(current_score)\n",
    "    \n",
    "    if current_score < best_score:\n",
    "        best_score = current_score\n",
    "        best_grid = g\n",
    "        best_history = siamese.hist.history\n",
    "        print(\"Score:\", best_score, \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
