{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from moge.network.heterogeneous_network import HeterogeneousNetwork\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# READ\n",
    "with open('moge/data/LMN_future_recall/TRAIN/Interactions_Affinity/LMN_mirtarbase_biogrid_starbase_lncrna2target_lncrinter.train.pickle', 'rb') as file:\n",
    "    network = pickle.load(file)\n",
    "    \n",
    "with open('moge/data/LMN_future_recall/TEST/Interactions_Affinity/LMN_mirtarbase_biogrid_starbase_lncrna2target_lncrinter.test.pickle', 'rb') as file:\n",
    "    network_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"d\": [128, 512],\n",
    "    \"lr\": [0.001, 0.0005],\n",
    "#     \"margin\": [0.1, 0.2, 0.5],\n",
    "#     \"compression_func\": [\"sqrt\", \"log\"],\n",
    "    \"negative_sampling_ratio\": [2.0, 5.0, 8.0],\n",
    "#     \"directed_proba\": [0.5, 0.8],\n",
    "    \"max_length\": [1400, 1800],\n",
    "    \"truncating\": [\"random\", \"post\"],\n",
    "    \n",
    "    \"conv1_kernel_size\": [6, 12, 18],\n",
    "    \"max1_pool_size\": [3, 4, 6],\n",
    "    \"conv2_kernel_size\": [None, 2, 4, 6],\n",
    "    \"max2_pool_size\": [2, 4, 6],\n",
    "    \"lstm_unit_size\": [160, 320],\n",
    "    \"dense1_unit_size\": [256, 1024],\n",
    "    \"dense2_unit_size\": [None, 256, 512],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from moge.embedding.siamese_graph_embedding import SiameseGraphEmbedding, SiameseTripletGraphEmbedding\n",
    "\n",
    "siamese = SiameseGraphEmbedding(batch_size=925, epochs=1, verbose=False)\n",
    "\n",
    "# siamese = SiameseTripletGraphEmbedding(batch_size=256, epochs=1, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'truncating': 'random', 'negative_sampling_ratio': 8.0, 'max_length': 1400, 'max2_pool_size': 4, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': 512, 'dense1_unit_size': 1024, 'd': 128, 'conv2_kernel_size': None, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1762s 260ms/step - loss: 0.0809 - val_loss: 0.1838\n",
      "Score: 0.18375178881381687 \n",
      "\n",
      "{'truncating': 'post', 'negative_sampling_ratio': 5.0, 'max_length': 1400, 'max2_pool_size': 2, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': 256, 'dense1_unit_size': 1024, 'd': 512, 'conv2_kernel_size': None, 'conv1_kernel_size': 6}\n",
      "Epoch 1/1\n",
      "6782/6783 [============================>.] - ETA: 0s - loss: 0.0835Epoch 1/1\n",
      "6783/6783 [==============================] - 1797s 265ms/step - loss: 0.0835 - val_loss: 0.1891\n",
      "Epoch 1/1\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 2.0, 'max_length': 1800, 'max2_pool_size': 6, 'max1_pool_size': 4, 'lstm_unit_size': 160, 'lr': 0.001, 'dense2_unit_size': 512, 'dense1_unit_size': 256, 'd': 128, 'conv2_kernel_size': 6, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 983s 145ms/step - loss: 0.0789 - val_loss: 0.1845\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 5.0, 'max_length': 1400, 'max2_pool_size': 2, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': None, 'dense1_unit_size': 256, 'd': 128, 'conv2_kernel_size': None, 'conv1_kernel_size': 6}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1777s 262ms/step - loss: 0.0838 - val_loss: 0.1778\n",
      "\n",
      "Score: 0.1778403219423796 \n",
      "\n",
      "{'truncating': 'post', 'negative_sampling_ratio': 2.0, 'max_length': 1800, 'max2_pool_size': 4, 'max1_pool_size': 4, 'lstm_unit_size': 320, 'lr': 0.001, 'dense2_unit_size': 512, 'dense1_unit_size': 1024, 'd': 512, 'conv2_kernel_size': None, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 2519s 371ms/step - loss: 0.0895 - val_loss: 0.1801\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 8.0, 'max_length': 1800, 'max2_pool_size': 4, 'max1_pool_size': 3, 'lstm_unit_size': 320, 'lr': 0.001, 'dense2_unit_size': 512, 'dense1_unit_size': 256, 'd': 128, 'conv2_kernel_size': 2, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1324s 195ms/step - loss: 0.0794 - val_loss: 0.1794\n",
      "\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 8.0, 'max_length': 1800, 'max2_pool_size': 2, 'max1_pool_size': 4, 'lstm_unit_size': 160, 'lr': 0.001, 'dense2_unit_size': 256, 'dense1_unit_size': 1024, 'd': 128, 'conv2_kernel_size': 6, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1187s 175ms/step - loss: 0.0766 - val_loss: 0.1747\n",
      "Score: 0.17467667625138633 \n",
      "\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 8.0, 'max_length': 1400, 'max2_pool_size': 6, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': None, 'dense1_unit_size': 256, 'd': 512, 'conv2_kernel_size': None, 'conv1_kernel_size': 6}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1792s 264ms/step - loss: 0.0845 - val_loss: 0.1760\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 2.0, 'max_length': 1800, 'max2_pool_size': 4, 'max1_pool_size': 6, 'lstm_unit_size': 320, 'lr': 0.0005, 'dense2_unit_size': 256, 'dense1_unit_size': 256, 'd': 128, 'conv2_kernel_size': 4, 'conv1_kernel_size': 18}\n",
      "Epoch 1/1\n",
      "6783/6783 [==============================] - 1028s 152ms/step - loss: 0.0760 - val_loss: 0.1738\n",
      "Score: 0.1737694202285064 \n",
      "\n",
      "{'truncating': 'random', 'negative_sampling_ratio': 8.0, 'max_length': 1800, 'max2_pool_size': 4, 'max1_pool_size': 3, 'lstm_unit_size': 160, 'lr': 0.001, 'dense2_unit_size': 512, 'dense1_unit_size': 1024, 'd': 512, 'conv2_kernel_size': None, 'conv1_kernel_size': 12}\n",
      "Epoch 1/1\n",
      "   7/6783 [..............................] - ETA: 1:59:16 - loss: 0.6681"
     ]
    }
   ],
   "source": [
    "best_score = float(\"inf\")\n",
    "X_params = []\n",
    "y = []\n",
    "\n",
    "for g in ParameterSampler(parameters, n_iter=300):\n",
    "    print(g)\n",
    "    siamese.set_params(**g)\n",
    "    \n",
    "    try:\n",
    "        siamese.learn_embedding(network, network_val=network_val, multi_gpu=True, \n",
    "                            subsample=False, n_steps=1000, validation_steps=None, \n",
    "                            validation_make_data=False, rebuild_model=True,\n",
    "                            seed=42)\n",
    "    except Exception as e:\n",
    "        print(\"Failed!!!\", e)\n",
    "        continue\n",
    "    except KeyboardInterrupt as e:\n",
    "        continue\n",
    "    \n",
    "    current_score = siamese.hist.history['val_loss'][-1]\n",
    "    X_params.append(g)\n",
    "    y.append(current_score)\n",
    "    \n",
    "    if current_score < best_score:\n",
    "        best_score = current_score\n",
    "        best_grid = g\n",
    "        best_history = siamese.hist.history\n",
    "        print(\"Score:\", best_score, \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
